{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khaarl/VIZDOOM1/blob/main/VISDOOMGPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "+-----------------------------------------------------------------------------+\n",
        "| |       |\\                                           -~ /     \\  /          |\n",
        "|~~__     | \\                                         | \\/       /\\          /|\n",
        "|    --   |  \\                                        | / \\    /    \\     /   |\n",
        "|      |~_|   \\                                   \\___|/    \\/         /      |\n",
        "|--__  |   -- |\\________________________________/~~\\~~|    /  \\     /     \\   |\n",
        "|   |~~--__  |~_|____|____|____|____|____|____|/ /  \\/|\\ /      \\/          \\/|\n",
        "|   |      |~--_|__|____|____|____|____|____|_/ /|    |/ \\    /   \\       /   |\n",
        "|___|______|__|_||____|____|____|____|____|__[]/_|----|    \\/       \\  /      |\n",
        "|  \\mmmm :   | _|___|____|____|____|____|____|___|  /\\|   /  \\      /  \\      |\n",
        "|      B :_--~~ |_|____|____|____|____|____|____|  |  |\\/      \\ /        \\   |\n",
        "|  __--P :  |  /                                /  /  | \\     /  \\          /\\|\n",
        "|~~  |   :  | /                                 ~~~   |  \\  /      \\      /   |\n",
        "|    |      |/                        .-.             |  /\\          \\  /     |\n",
        "|    |      /                        |   |            |/   \\          /\\      |\n",
        "|    |     /                        |     |            -_   \\       /    \\    |\n",
        "+-----------------------------------------------------------------------------+\n",
        "|          |  /|  |   |  2  3  4  | /~~~~~\\ |       /|    |_| ....  ......... |\n",
        "|          |  ~|~ | % |           | | ~J~ | |       ~|~ % |_| ....  ......... |\n",
        "|   AMMO   |  HEALTH  |  5  6  7  |  \\===/  |    ARMOR    |#| ....  ......... |\n",
        "+-----------------------------------------------------------------------------+"
      ],
      "metadata": {
        "id": "uKWem7K5d_mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7852EWnX1Zc",
        "outputId": "502e5b52-dca5-4d5e-fd24-363975d29a54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [61.7 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,199 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,631 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,226 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,513 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,554 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,854 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,517 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,652 kB]\n",
            "Fetched 19.6 MB in 7s (2,730 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "libjpeg-dev is already the newest version (8c-2ubuntu10).\n",
            "libjpeg-dev set to manually installed.\n",
            "libpng-dev is already the newest version (1.6.37-3build5).\n",
            "libboost-all-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.11).\n",
            "libpython3-dev is already the newest version (3.10.6-1~22.04.1).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-2ubuntu9.2).\n",
            "zlib1g-dev set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  gir1.2-ibus-1.0 libblkid-dev libblkid1 libdbus-1-dev libdecor-0-dev libdrm-dev libegl-dev\n",
            "  libegl1-mesa-dev libffi-dev libgbm-dev libgl-dev libgles-dev libgles1 libglib2.0-dev\n",
            "  libglib2.0-dev-bin libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev libglx-dev\n",
            "  libibus-1.0-5 libibus-1.0-dev libice-dev libmount-dev libmount1 libopengl-dev libpciaccess-dev\n",
            "  libpulse-dev libpulse-mainloop-glib0 libselinux1-dev libsepol-dev libsm-dev libsndio-dev\n",
            "  libudev-dev libudev1 libwayland-bin libwayland-dev libxcursor-dev libxfixes-dev libxi-dev\n",
            "  libxinerama-dev libxkbcommon-dev libxrandr-dev libxt-dev libxv-dev libxxf86vm-dev\n",
            "Suggested packages:\n",
            "  libgirepository1.0-dev libglib2.0-doc libgdk-pixbuf2.0-bin | libgdk-pixbuf2.0-dev libxml2-utils\n",
            "  libice-doc cryptsetup-bin libsm-doc libwayland-doc libxt-doc\n",
            "The following NEW packages will be installed:\n",
            "  gir1.2-ibus-1.0 libblkid-dev libdbus-1-dev libdecor-0-dev libdrm-dev libegl-dev libegl1-mesa-dev\n",
            "  libffi-dev libgbm-dev libgl-dev libgles-dev libgles1 libglib2.0-dev libglib2.0-dev-bin\n",
            "  libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev libglx-dev libibus-1.0-5\n",
            "  libibus-1.0-dev libice-dev libmount-dev libopengl-dev libpciaccess-dev libpulse-dev\n",
            "  libpulse-mainloop-glib0 libsdl2-dev libselinux1-dev libsepol-dev libsm-dev libsndio-dev\n",
            "  libudev-dev libwayland-bin libwayland-dev libxcursor-dev libxfixes-dev libxi-dev libxinerama-dev\n",
            "  libxkbcommon-dev libxrandr-dev libxt-dev libxv-dev libxxf86vm-dev\n",
            "The following packages will be upgraded:\n",
            "  libblkid1 libmount1 libudev1\n",
            "3 upgraded, 44 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 7,357 kB of archives.\n",
            "After this operation, 40.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libblkid1 amd64 2.37.2-4ubuntu3.4 [103 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmount1 amd64 2.37.2-4ubuntu3.4 [122 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.12 [78.2 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libibus-1.0-5 amd64 1.5.26-4 [183 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 gir1.2-ibus-1.0 amd64 1.5.26-4 [88.3 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-dev amd64 1.12.20-2ubuntu4.1 [188 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libwayland-bin amd64 1.20.0-1ubuntu0.1 [20.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libffi-dev amd64 3.4.2-4 [63.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libwayland-dev amd64 1.20.0-1ubuntu0.1 [69.5 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdecor-0-dev amd64 0.1.0-3build1 [5,544 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpciaccess-dev amd64 0.16-3 [21.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdrm-dev amd64 2.4.113-2~ubuntu0.22.04.1 [292 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libegl1-mesa-dev amd64 23.2.1-1ubuntu3.1~22.04.3 [11.1 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgbm-dev amd64 23.2.1-1ubuntu3.1~22.04.3 [9,542 B]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-dev-bin amd64 2.72.4-0ubuntu2.4 [117 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libblkid-dev amd64 2.37.2-4ubuntu3.4 [185 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsepol-dev amd64 3.3-1build1 [378 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 libselinux1-dev amd64 3.3-1build2 [158 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmount-dev amd64 2.37.2-4ubuntu3.4 [14.5 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-dev amd64 2.72.4-0ubuntu2.4 [1,743 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libibus-1.0-dev amd64 1.5.26-4 [185 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpulse-mainloop-glib0 amd64 1:15.99.1+dfsg1-1ubuntu2.2 [12.4 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpulse-dev amd64 1:15.99.1+dfsg1-1ubuntu2.2 [75.6 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libsndio-dev amd64 1.8.1-1.1 [17.8 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev-dev amd64 249.11-0ubuntu3.12 [20.7 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfixes-dev amd64 1:6.0.0-1 [12.2 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcursor-dev amd64 1:1.2.0-2build4 [28.2 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxi-dev amd64 2:1.8-1build1 [193 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxinerama-dev amd64 2:1.1.4-3 [8,104 B]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-dev amd64 1.4.0-1 [54.9 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxrandr-dev amd64 2:1.5.2-1build1 [26.7 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxv-dev amd64 2:1.0.11-1build2 [33.4 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86vm-dev amd64 1:1.1.4-1build3 [13.9 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsdl2-dev amd64 2.0.20+dfsg-2ubuntu1.22.04.1 [1,767 kB]\n",
            "Fetched 7,357 kB in 6s (1,267 kB/s)\n",
            "Extracting templates from packages: 100%\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../libblkid1_2.37.2-4ubuntu3.4_amd64.deb ...\n",
            "Unpacking libblkid1:amd64 (2.37.2-4ubuntu3.4) over (2.37.2-4ubuntu3) ...\n",
            "Setting up libblkid1:amd64 (2.37.2-4ubuntu3.4) ...\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../libmount1_2.37.2-4ubuntu3.4_amd64.deb ...\n",
            "Unpacking libmount1:amd64 (2.37.2-4ubuntu3.4) over (2.37.2-4ubuntu3) ...\n",
            "Setting up libmount1:amd64 (2.37.2-4ubuntu3.4) ...\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.12) over (249.11-0ubuntu3.10) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package libibus-1.0-5:amd64.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libibus-1.0-5_1.5.26-4_amd64.deb ...\n",
            "Unpacking libibus-1.0-5:amd64 (1.5.26-4) ...\n",
            "Selecting previously unselected package gir1.2-ibus-1.0:amd64.\n",
            "Preparing to unpack .../01-gir1.2-ibus-1.0_1.5.26-4_amd64.deb ...\n",
            "Unpacking gir1.2-ibus-1.0:amd64 (1.5.26-4) ...\n",
            "Selecting previously unselected package libdbus-1-dev:amd64.\n",
            "Preparing to unpack .../02-libdbus-1-dev_1.12.20-2ubuntu4.1_amd64.deb ...\n",
            "Unpacking libdbus-1-dev:amd64 (1.12.20-2ubuntu4.1) ...\n",
            "Selecting previously unselected package libwayland-bin.\n",
            "Preparing to unpack .../03-libwayland-bin_1.20.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libwayland-bin (1.20.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libffi-dev:amd64.\n",
            "Preparing to unpack .../04-libffi-dev_3.4.2-4_amd64.deb ...\n",
            "Unpacking libffi-dev:amd64 (3.4.2-4) ...\n",
            "Selecting previously unselected package libwayland-dev:amd64.\n",
            "Preparing to unpack .../05-libwayland-dev_1.20.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libwayland-dev:amd64 (1.20.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libdecor-0-dev:amd64.\n",
            "Preparing to unpack .../06-libdecor-0-dev_0.1.0-3build1_amd64.deb ...\n",
            "Unpacking libdecor-0-dev:amd64 (0.1.0-3build1) ...\n",
            "Selecting previously unselected package libpciaccess-dev:amd64.\n",
            "Preparing to unpack .../07-libpciaccess-dev_0.16-3_amd64.deb ...\n",
            "Unpacking libpciaccess-dev:amd64 (0.16-3) ...\n",
            "Selecting previously unselected package libdrm-dev:amd64.\n",
            "Preparing to unpack .../08-libdrm-dev_2.4.113-2~ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libdrm-dev:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "Preparing to unpack .../09-libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../10-libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl-dev:amd64.\n",
            "Preparing to unpack .../11-libegl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
            "Preparing to unpack .../12-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../13-libgles1_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../14-libgles-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../15-libopengl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../16-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../17-libegl1-mesa-dev_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking libegl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Selecting previously unselected package libgbm-dev:amd64.\n",
            "Preparing to unpack .../18-libgbm-dev_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking libgbm-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Selecting previously unselected package libglib2.0-dev-bin.\n",
            "Preparing to unpack .../19-libglib2.0-dev-bin_2.72.4-0ubuntu2.4_amd64.deb ...\n",
            "Unpacking libglib2.0-dev-bin (2.72.4-0ubuntu2.4) ...\n",
            "Selecting previously unselected package libblkid-dev:amd64.\n",
            "Preparing to unpack .../20-libblkid-dev_2.37.2-4ubuntu3.4_amd64.deb ...\n",
            "Unpacking libblkid-dev:amd64 (2.37.2-4ubuntu3.4) ...\n",
            "Selecting previously unselected package libsepol-dev:amd64.\n",
            "Preparing to unpack .../21-libsepol-dev_3.3-1build1_amd64.deb ...\n",
            "Unpacking libsepol-dev:amd64 (3.3-1build1) ...\n",
            "Selecting previously unselected package libselinux1-dev:amd64.\n",
            "Preparing to unpack .../22-libselinux1-dev_3.3-1build2_amd64.deb ...\n",
            "Unpacking libselinux1-dev:amd64 (3.3-1build2) ...\n",
            "Selecting previously unselected package libmount-dev:amd64.\n",
            "Preparing to unpack .../23-libmount-dev_2.37.2-4ubuntu3.4_amd64.deb ...\n",
            "Unpacking libmount-dev:amd64 (2.37.2-4ubuntu3.4) ...\n",
            "Selecting previously unselected package libglib2.0-dev:amd64.\n",
            "Preparing to unpack .../24-libglib2.0-dev_2.72.4-0ubuntu2.4_amd64.deb ...\n",
            "Unpacking libglib2.0-dev:amd64 (2.72.4-0ubuntu2.4) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../25-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglu1-mesa-dev:amd64.\n",
            "Preparing to unpack .../26-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libibus-1.0-dev:amd64.\n",
            "Preparing to unpack .../27-libibus-1.0-dev_1.5.26-4_amd64.deb ...\n",
            "Unpacking libibus-1.0-dev:amd64 (1.5.26-4) ...\n",
            "Selecting previously unselected package libice-dev:amd64.\n",
            "Preparing to unpack .../28-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n",
            "Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Selecting previously unselected package libpulse-mainloop-glib0:amd64.\n",
            "Preparing to unpack .../29-libpulse-mainloop-glib0_1%3a15.99.1+dfsg1-1ubuntu2.2_amd64.deb ...\n",
            "Unpacking libpulse-mainloop-glib0:amd64 (1:15.99.1+dfsg1-1ubuntu2.2) ...\n",
            "Selecting previously unselected package libpulse-dev:amd64.\n",
            "Preparing to unpack .../30-libpulse-dev_1%3a15.99.1+dfsg1-1ubuntu2.2_amd64.deb ...\n",
            "Unpacking libpulse-dev:amd64 (1:15.99.1+dfsg1-1ubuntu2.2) ...\n",
            "Selecting previously unselected package libsndio-dev:amd64.\n",
            "Preparing to unpack .../31-libsndio-dev_1.8.1-1.1_amd64.deb ...\n",
            "Unpacking libsndio-dev:amd64 (1.8.1-1.1) ...\n",
            "Selecting previously unselected package libudev-dev:amd64.\n",
            "Preparing to unpack .../32-libudev-dev_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking libudev-dev:amd64 (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package libxfixes-dev:amd64.\n",
            "Preparing to unpack .../33-libxfixes-dev_1%3a6.0.0-1_amd64.deb ...\n",
            "Unpacking libxfixes-dev:amd64 (1:6.0.0-1) ...\n",
            "Selecting previously unselected package libxcursor-dev:amd64.\n",
            "Preparing to unpack .../34-libxcursor-dev_1%3a1.2.0-2build4_amd64.deb ...\n",
            "Unpacking libxcursor-dev:amd64 (1:1.2.0-2build4) ...\n",
            "Selecting previously unselected package libxi-dev:amd64.\n",
            "Preparing to unpack .../35-libxi-dev_2%3a1.8-1build1_amd64.deb ...\n",
            "Unpacking libxi-dev:amd64 (2:1.8-1build1) ...\n",
            "Selecting previously unselected package libxinerama-dev:amd64.\n",
            "Preparing to unpack .../36-libxinerama-dev_2%3a1.1.4-3_amd64.deb ...\n",
            "Unpacking libxinerama-dev:amd64 (2:1.1.4-3) ...\n",
            "Selecting previously unselected package libxkbcommon-dev:amd64.\n",
            "Preparing to unpack .../37-libxkbcommon-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libxrandr-dev:amd64.\n",
            "Preparing to unpack .../38-libxrandr-dev_2%3a1.5.2-1build1_amd64.deb ...\n",
            "Unpacking libxrandr-dev:amd64 (2:1.5.2-1build1) ...\n",
            "Selecting previously unselected package libsm-dev:amd64.\n",
            "Preparing to unpack .../39-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n",
            "Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../40-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package libxv-dev:amd64.\n",
            "Preparing to unpack .../41-libxv-dev_2%3a1.0.11-1build2_amd64.deb ...\n",
            "Unpacking libxv-dev:amd64 (2:1.0.11-1build2) ...\n",
            "Selecting previously unselected package libxxf86vm-dev:amd64.\n",
            "Preparing to unpack .../42-libxxf86vm-dev_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libxxf86vm-dev:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libsdl2-dev:amd64.\n",
            "Preparing to unpack .../43-libsdl2-dev_2.0.20+dfsg-2ubuntu1.22.04.1_amd64.deb ...\n",
            "Unpacking libsdl2-dev:amd64 (2.0.20+dfsg-2ubuntu1.22.04.1) ...\n",
            "Setting up libglib2.0-dev-bin (2.72.4-0ubuntu2.4) ...\n",
            "Setting up libblkid-dev:amd64 (2.37.2-4ubuntu3.4) ...\n",
            "Setting up libsndio-dev:amd64 (1.8.1-1.1) ...\n",
            "Setting up libpciaccess-dev:amd64 (0.16-3) ...\n",
            "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Setting up libxxf86vm-dev:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libxkbcommon-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libibus-1.0-5:amd64 (1.5.26-4) ...\n",
            "Setting up libffi-dev:amd64 (3.4.2-4) ...\n",
            "Setting up libgbm-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up libxfixes-dev:amd64 (1:6.0.0-1) ...\n",
            "Setting up libxv-dev:amd64 (2:1.0.11-1build2) ...\n",
            "Setting up libwayland-bin (1.20.0-1ubuntu0.1) ...\n",
            "Setting up libxrandr-dev:amd64 (2:1.5.2-1build1) ...\n",
            "Setting up libdbus-1-dev:amd64 (1.12.20-2ubuntu4.1) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up libpulse-mainloop-glib0:amd64 (1:15.99.1+dfsg1-1ubuntu2.2) ...\n",
            "Setting up libgles1:amd64 (1.4.0-1) ...\n",
            "Setting up libudev-dev:amd64 (249.11-0ubuntu3.12) ...\n",
            "Setting up libxinerama-dev:amd64 (2:1.1.4-3) ...\n",
            "Setting up libsepol-dev:amd64 (3.3-1build1) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libxi-dev:amd64 (2:1.8-1build1) ...\n",
            "Setting up gir1.2-ibus-1.0:amd64 (1.5.26-4) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libdrm-dev:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
            "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libselinux1-dev:amd64 (3.3-1build2) ...\n",
            "Setting up libxcursor-dev:amd64 (1:1.2.0-2build4) ...\n",
            "Setting up libwayland-dev:amd64 (1.20.0-1ubuntu0.1) ...\n",
            "Setting up libdecor-0-dev:amd64 (0.1.0-3build1) ...\n",
            "Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libmount-dev:amd64 (2.37.2-4ubuntu3.4) ...\n",
            "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglib2.0-dev:amd64 (2.72.4-0ubuntu2.4) ...\n",
            "Setting up libegl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.4) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Setting up libibus-1.0-dev:amd64 (1.5.26-4) ...\n",
            "Setting up libpulse-dev:amd64 (1:15.99.1+dfsg1-1ubuntu2.2) ...\n",
            "Setting up libsdl2-dev:amd64 (2.0.20+dfsg-2ubuntu1.22.04.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# --- Setup ---\n",
        "!apt-get update -y\n",
        "!apt-get install -y build-essential cmake git libboost-all-dev libsdl2-dev libjpeg-dev libpng-dev zlib1g-dev libpython3-dev\n",
        "\n",
        "!apt-get install ffmpeg\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "# Use Mesa for software rendering (CPU-based)\n",
        "os.environ['LIBGL_ALWAYS_SOFTWARE'] = '1'\n",
        "\n",
        "# Set XDG_RUNTIME_DIR to avoid other SDL issues\n",
        "os.environ['XDG_RUNTIME_DIR'] = '/tmp'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtIdiASZX82K",
        "outputId": "372dd0c5-4dc9-43cc-be46-517abfa2052e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping vizdoom as it is not installed.\u001b[0m\u001b[33m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libboost-python-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-python-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Cloning into 'ViZDoom'...\n",
            "remote: Enumerating objects: 18734, done.\u001b[K\n",
            "remote: Counting objects: 100% (567/567), done.\u001b[K\n",
            "remote: Compressing objects: 100% (198/198), done.\u001b[K\n",
            "remote: Total 18734 (delta 469), reused 369 (delta 369), pack-reused 18167 (from 5)\u001b[K\n",
            "Receiving objects: 100% (18734/18734), 59.90 MiB | 14.57 MiB/s, done.\n",
            "Resolving deltas: 100% (11722/11722), done.\n",
            "/content/ViZDoom\n",
            "\u001b[33mCMake Warning:\n",
            "  Ignoring extra path from command line:\n",
            "\n",
            "   \"..\"\n",
            "\n",
            "\u001b[0m\n",
            "\u001b[0mCMake Error: The source directory \"/content\" does not appear to contain CMakeLists.txt.\n",
            "Specify --help for usage, or press the help button on the CMake GUI.\u001b[0m\n",
            "make: *** No rule to make target 'install'.  Stop.\n",
            "/content\n",
            "Collecting vizdoom\n",
            "  Downloading vizdoom-1.2.4-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vizdoom) (1.26.4)\n",
            "Collecting gymnasium>=0.28.0 (from vizdoom)\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from vizdoom) (2.6.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->vizdoom) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->vizdoom) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium>=0.28.0->vizdoom)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Downloading vizdoom-1.2.4-cp310-cp310-manylinux_2_28_x86_64.whl (28.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.1/28.1 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium, vizdoom\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0 vizdoom-1.2.4\n"
          ]
        }
      ],
      "source": [
        "# --- Install ViZDoom from source (for proper linking) ---\n",
        "!pip uninstall -y vizdoom\n",
        "!apt-get install -y libboost-python-dev\n",
        "!git clone https://github.com/mwydmuch/ViZDoom.git\n",
        "%cd ViZDoom\n",
        "!mkdir build && cd build\n",
        "!cmake .. -DBUILD_PYTHON=ON -DCMAKE_INSTALL_PREFIX=/usr/local\n",
        "!make -j$(nproc) install\n",
        "%cd /content\n",
        "!pip install vizdoom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zK1wHVDGX-os",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90185c04-32f2-4a7b-88ec-32cb2c11ca36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose a WAD file to use:\n",
            "1. Use current scenario WAD (defend_the_center.cfg with vizdoom assets)\n",
            "2. Use original Doom WAD from Google Drive (ViZDoomWADs folder with defend_the_center.cfg)\n",
            "Enter your choice (1 or 2): 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-07 14:43:47,857 - INFO - WAD Choice: 1\n",
            "INFO:__main__:WAD Choice: 1\n",
            "2025-01-07 14:43:47,861 - INFO - Using default scenario path: /usr/local/lib/python3.10/dist-packages/vizdoom/scenarios/defend_the_center.cfg\n",
            "INFO:__main__:Using default scenario path: /usr/local/lib/python3.10/dist-packages/vizdoom/scenarios/defend_the_center.cfg\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Select Run Mode:\n",
            "1. Quick Run (Default settings)\n",
            "2. Custom Run (Configure all settings)\n",
            "Enter your choice (1 or 2): 1\n",
            "\n",
            "Model Selection:\n",
            "1. Create new model\n",
            "2. Load existing model\n",
            "Enter choice (1 or 2): 2\n",
            "Enter number of episodes (default=1): 11\n",
            "Enter model save frequency (default=1): 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-07 14:44:05,271 - INFO - ViZDoom initialized successfully.\n",
            "INFO:__main__:ViZDoom initialized successfully.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available models:\n",
            "1. 202501051506_dqn_model_episode_1.pth\n",
            "2. 202501051520_dqn_model_episode_1.pth\n",
            "3. 202501051530_dqn_model_episode_1.pth\n",
            "4. 202501051546_dqn_model_episode_1.pth\n",
            "5. 202501051604_dqn_model_episode_1.pth\n",
            "6. 202501051636_dqn_model_episode_1.pth\n",
            "7. 202501051721_dqn_model_episode_6.pth\n",
            "8. 202501051836_dqn_model_episode_1.pth\n",
            "9. 202501051908_dqn_model_episode_1.pth\n",
            "10. 202501051918_dqn_model_episode_2.pth\n",
            "11. 202501051959_dqn_model_episode_1.pth\n",
            "12. 202501052008_dqn_model_episode_1.pth\n",
            "13. 202501052026_dqn_model_episode_1.pth\n",
            "14. 202501052031_dqn_model_episode_1.pth\n",
            "15. 202501052035_dqn_model_episode_1.pth\n",
            "16. 202501052050_dqn_model_episode_1.pth\n",
            "17. 202501052051_dqn_model_episode_2.pth\n",
            "18. 202501052052_dqn_model_episode_1.pth\n",
            "19. 202501052055_dqn_model_episode_1.pth\n",
            "20. 202501052058_dqn_model_episode_3.pth\n",
            "21. 202501052100_dqn_model_episode_1.pth\n",
            "22. 202501052112_dqn_model_episode_1.pth\n",
            "23. 202501052151_dqn_model_episode_1.pth\n",
            "24. dqn_model_episode_0.pth\n",
            "25. best_dqn_model.pth\n",
            "26. model_episode_10.pth\n",
            "27. model_episode_1.pth\n",
            "28. model_episode_5.pth\n",
            "29. Create new model\n",
            "Enter your choice: 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-1ae809828089>:529: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_path, map_location=self.device)\n",
            "2025-01-07 14:44:22,796 - INFO - Model loaded from /content/drive/My Drive/ViZDoomModels/model_episode_5.pth\n",
            "INFO:__main__:Model loaded from /content/drive/My Drive/ViZDoomModels/model_episode_5.pth\n",
            "2025-01-07 14:44:22,805 - INFO - Video Writer set up at: /content/drive/My Drive/ViZDoomRecordings/game_recording.mp4\n",
            "INFO:__main__:Video Writer set up at: /content/drive/My Drive/ViZDoomRecordings/game_recording.mp4\n",
            "2025-01-07 14:44:22,808 - INFO - TensorBoard logging to: logs/202501071444_experiment\n",
            "INFO:__main__:TensorBoard logging to: logs/202501071444_experiment\n",
            "2025-01-07 14:44:25,367 - INFO - Best model saved to /content/drive/My Drive/ViZDoomModels/best_dqn_model.pth with reward: 0.0\n",
            "INFO:__main__:Best model saved to /content/drive/My Drive/ViZDoomModels/best_dqn_model.pth with reward: 0.0\n",
            "2025-01-07 14:44:25,372 - INFO - Episode 1/10: Reward=0.00, Steps=78, Epsilon=1.000\n",
            "INFO:__main__:Episode 1/10: Reward=0.00, Steps=78, Epsilon=1.000\n",
            "2025-01-07 14:44:28,623 - INFO - Episode 2/10: Reward=0.00, Steps=67, Epsilon=1.000\n",
            "INFO:__main__:Episode 2/10: Reward=0.00, Steps=67, Epsilon=1.000\n",
            "2025-01-07 14:44:32,610 - INFO - Episode 3/10: Reward=-1.00, Steps=69, Epsilon=1.000\n",
            "INFO:__main__:Episode 3/10: Reward=-1.00, Steps=69, Epsilon=1.000\n",
            "2025-01-07 14:44:38,351 - INFO - Episode 4/10: Reward=1.00, Steps=97, Epsilon=1.000\n",
            "INFO:__main__:Episode 4/10: Reward=1.00, Steps=97, Epsilon=1.000\n",
            "2025-01-07 14:44:41,738 - INFO - Best model saved to /content/drive/My Drive/ViZDoomModels/best_dqn_model.pth with reward: 0.2\n",
            "INFO:__main__:Best model saved to /content/drive/My Drive/ViZDoomModels/best_dqn_model.pth with reward: 0.2\n",
            "2025-01-07 14:44:41,750 - INFO - Episode 5/10: Reward=1.00, Steps=69, Epsilon=1.000\n",
            "INFO:__main__:Episode 5/10: Reward=1.00, Steps=69, Epsilon=1.000\n",
            "2025-01-07 14:44:47,027 - INFO - Best model saved to /content/drive/My Drive/ViZDoomModels/best_dqn_model.pth with reward: 0.3333333333333333\n",
            "INFO:__main__:Best model saved to /content/drive/My Drive/ViZDoomModels/best_dqn_model.pth with reward: 0.3333333333333333\n",
            "2025-01-07 14:44:47,043 - INFO - Episode 6/10: Reward=1.00, Steps=105, Epsilon=1.000\n",
            "INFO:__main__:Episode 6/10: Reward=1.00, Steps=105, Epsilon=1.000\n",
            "2025-01-07 14:44:50,879 - INFO - Episode 7/10: Reward=0.00, Steps=55, Epsilon=1.000\n",
            "INFO:__main__:Episode 7/10: Reward=0.00, Steps=55, Epsilon=1.000\n",
            "2025-01-07 14:44:56,986 - INFO - Best model saved to /content/drive/My Drive/ViZDoomModels/best_dqn_model.pth with reward: 0.375\n",
            "INFO:__main__:Best model saved to /content/drive/My Drive/ViZDoomModels/best_dqn_model.pth with reward: 0.375\n",
            "2025-01-07 14:44:56,994 - INFO - Episode 8/10: Reward=1.00, Steps=105, Epsilon=1.000\n",
            "INFO:__main__:Episode 8/10: Reward=1.00, Steps=105, Epsilon=1.000\n",
            "2025-01-07 14:45:00,628 - INFO - Episode 9/10: Reward=-1.00, Steps=69, Epsilon=1.000\n",
            "INFO:__main__:Episode 9/10: Reward=-1.00, Steps=69, Epsilon=1.000\n",
            "2025-01-07 14:45:04,793 - INFO - Model saved at episode 10\n",
            "INFO:__main__:Model saved at episode 10\n",
            "2025-01-07 14:45:04,798 - INFO - Episode 10/10: Reward=-1.00, Steps=67, Epsilon=1.000\n",
            "INFO:__main__:Episode 10/10: Reward=-1.00, Steps=67, Epsilon=1.000\n",
            "2025-01-07 14:45:05,163 - INFO - Training metrics saved to /content/drive/My Drive/ViZDoomModels/202501071445_training_metrics.csv\n",
            "INFO:__main__:Training metrics saved to /content/drive/My Drive/ViZDoomModels/202501071445_training_metrics.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'type': 'setting', 'settings': {'python.logging.level': 'INFO'}}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import yaml\n",
        "import shutil\n",
        "import time\n",
        "import random\n",
        "import logging\n",
        "import glob\n",
        "import psutil\n",
        "import gc\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import imageio\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from copy import deepcopy\n",
        "from vizdoom import DoomGame, ScreenFormat, ScreenResolution, Mode  # Import DoomGame\n",
        "\n",
        "# --- Create config.yaml if it doesn't exist ---\n",
        "CONFIG_PATH = \"config.yaml\"  # Path to your config file\n",
        "\n",
        "default_config = {\n",
        "    \"drive_model_dir\": \"/content/drive/My Drive/ViZDoomModels\",\n",
        "    \"drive_wad_dir\": \"/content/drive/My Drive/ViZDoomWADs\",\n",
        "    \"local_wad_dir\": \"/content/ViZDoomWADs\",\n",
        "    \"video_dir\": \"/content/drive/My Drive/ViZDoomRecordings\",\n",
        "    \"video_filename\": \"game_recording.mp4\",\n",
        "    \"record_lmp\": False,\n",
        "    \"record_video\": True,\n",
        "    \"video_fps\": 30,\n",
        "    \"lmp_dir\": \"lmp_recordings\",\n",
        "    \"scenario_name\": \"defend_the_center.cfg\",\n",
        "    \"stack_size\": 4,\n",
        "    \"num_episodes\": 10,\n",
        "    \"frame_skip_training\": 4,\n",
        "    \"frame_skip_recording\": 1,\n",
        "    \"gamma\": 0.99,\n",
        "    \"epsilon_start\": 1.0,\n",
        "    \"epsilon_end\": 0.05,\n",
        "    \"epsilon_decay\": 0.995,\n",
        "    \"model_save_freq\": 10,\n",
        "    \"batch_size\": 64,\n",
        "    \"memory_capacity\": 10000,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"tau\": 0.005,\n",
        "    \"n_step\": 3,\n",
        "    \"grad_clip_norm\": 1.0,\n",
        "    \"epsilon_decay_rate_step\": 1000,\n",
        "    \"use_best_model_callback\": True,\n",
        "    \"best_model_smoothing_window\": 10,\n",
        "    \"validation_episodes\": 5,\n",
        "}\n",
        "\n",
        "if not os.path.exists(CONFIG_PATH):\n",
        "    with open(CONFIG_PATH, 'w') as f:\n",
        "        yaml.dump(default_config, f)\n",
        "\n",
        "# --- Configuration Loading ---\n",
        "def load_config(config_path=CONFIG_PATH):\n",
        "    with open(config_path, 'r') as file:\n",
        "        return yaml.safe_load(file)\n",
        "\n",
        "CONFIG = load_config()\n",
        "\n",
        "# --- Logging Setup ---\n",
        "def setup_logger(log_dir, timestamp):\n",
        "    log_file = os.path.join(log_dir, f\"training_{timestamp}.log\")\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    # Clear any existing handlers\n",
        "    if logger.hasHandlers():\n",
        "        logger.handlers.clear()\n",
        "\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "\n",
        "    file_handler = logging.FileHandler(log_file)\n",
        "    file_handler.setLevel(logging.DEBUG)\n",
        "    stream_handler = logging.StreamHandler()\n",
        "    stream_handler.setLevel(logging.INFO)\n",
        "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "    file_handler.setFormatter(formatter)\n",
        "    stream_handler.setFormatter(formatter)\n",
        "    logger.addHandler(file_handler)\n",
        "    logger.addHandler(stream_handler)\n",
        "    return logger\n",
        "\n",
        "# --- Google Drive Setup ---\n",
        "DRIVE_MODEL_DIR = CONFIG[\"drive_model_dir\"]\n",
        "DRIVE_WAD_DIR = CONFIG[\"drive_wad_dir\"]\n",
        "LOCAL_WAD_DIR = CONFIG[\"local_wad_dir\"]\n",
        "VIDEO_DIR = CONFIG[\"video_dir\"]\n",
        "VIDEO_FILENAME = CONFIG[\"video_filename\"]\n",
        "VIDEO_PATH = os.path.join(VIDEO_DIR, VIDEO_FILENAME)\n",
        "\n",
        "# --- Configuration Variables ---\n",
        "RECORD_LMP = CONFIG[\"record_lmp\"]\n",
        "RECORD_VIDEO = CONFIG[\"record_video\"]\n",
        "VIDEO_FPS = CONFIG[\"video_fps\"]\n",
        "LMP_DIR = CONFIG[\"lmp_dir\"]\n",
        "SCENARIO_NAME = CONFIG[\"scenario_name\"]\n",
        "STACK_SIZE = CONFIG[\"stack_size\"]\n",
        "NUM_EPISODES = CONFIG[\"num_episodes\"]\n",
        "FRAME_SKIP_TRAINING = CONFIG[\"frame_skip_training\"]\n",
        "FRAME_SKIP_RECORDING = CONFIG[\"frame_skip_recording\"]\n",
        "\n",
        "# --- Training Parameters ---\n",
        "GAMMA = CONFIG[\"gamma\"]\n",
        "EPSILON_START = CONFIG[\"epsilon_start\"]\n",
        "EPSILON_END = CONFIG[\"epsilon_end\"]\n",
        "EPSILON_DECAY = CONFIG[\"epsilon_decay\"]\n",
        "MODEL_SAVE_FREQ = CONFIG[\"model_save_freq\"]\n",
        "BATCH_SIZE = CONFIG[\"batch_size\"]\n",
        "MEMORY_CAPACITY = CONFIG[\"memory_capacity\"]\n",
        "LEARNING_RATE = CONFIG[\"learning_rate\"]\n",
        "TAU = CONFIG[\"tau\"]\n",
        "N_STEP = CONFIG[\"n_step\"]\n",
        "GRAD_CLIP_NORM = CONFIG[\"grad_clip_norm\"]\n",
        "EPSILON_DECAY_RATE_STEP = CONFIG[\"epsilon_decay_rate_step\"]\n",
        "USE_BEST_MODEL_CALLBACK = CONFIG[\"use_best_model_callback\"]\n",
        "BEST_MODEL_SMOOTHING_WINDOW = CONFIG[\"best_model_smoothing_window\"]\n",
        "VALIDATION_EPISODES = CONFIG[\"validation_episodes\"]\n",
        "\n",
        "# --- Setup Google Drive ---\n",
        "def setup_google_drive(logger):\n",
        "    drive_mounted = os.path.exists('/content/drive/My Drive')\n",
        "    if not drive_mounted:\n",
        "        try:\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/drive')\n",
        "            logger.info(\"Google Drive mounted successfully.\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error mounting Google Drive: {e}\")\n",
        "            return False\n",
        "\n",
        "    os.makedirs(VIDEO_DIR, exist_ok=True)\n",
        "    os.makedirs(DRIVE_MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(DRIVE_WAD_DIR, exist_ok=True)\n",
        "    os.makedirs(LOCAL_WAD_DIR, exist_ok=True)\n",
        "    logger.info(\"Google Drive directories created successfully.\")\n",
        "    return True\n",
        "\n",
        "def copy_scenarios_to_drive(logger):\n",
        "    local_scenarios_dir = \"/usr/local/lib/python3.10/dist-packages/vizdoom/scenarios\"\n",
        "    wad_files = glob.glob(os.path.join(local_scenarios_dir, \"*.wad\"))\n",
        "    for wad_file in wad_files:\n",
        "        dest_file = os.path.join(DRIVE_WAD_DIR, os.path.basename(wad_file))\n",
        "        if os.path.exists(dest_file):\n",
        "            logger.info(f\"Skipped existing: {os.path.basename(wad_file)}\")\n",
        "        else:\n",
        "            try:\n",
        "                shutil.copy(wad_file, dest_file)\n",
        "                logger.info(f\"Copied: {os.path.basename(wad_file)}\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error copying: {os.path.basename(wad_file)}, error: {e}\")\n",
        "    return True\n",
        "\n",
        "# --- User Input for Recording ---\n",
        "def get_record_choices(logger):\n",
        "    logger.info(f\"Record LMP: {RECORD_LMP}, Record Video: {RECORD_VIDEO}\")\n",
        "    return RECORD_LMP, RECORD_VIDEO\n",
        "\n",
        "# --- User Input for Training Episodes ---\n",
        "def get_num_episodes(logger):\n",
        "    logger.info(f\"Number of Episodes: {NUM_EPISODES}\")\n",
        "    return NUM_EPISODES\n",
        "\n",
        "# --- User Input for FRAME_SKIP ---\n",
        "def get_frame_skips(logger):\n",
        "    FRAME_SKIP = FRAME_SKIP_TRAINING if not RECORD_VIDEO else FRAME_SKIP_RECORDING\n",
        "    logger.info(f\"Frame Skip Training: {FRAME_SKIP_TRAINING}, Frame Skip Recording: {FRAME_SKIP_RECORDING}\")\n",
        "    return FRAME_SKIP_TRAINING, FRAME_SKIP_RECORDING, FRAME_SKIP\n",
        "\n",
        "def get_wad_choice(logger):\n",
        "    print(\"Choose a WAD file to use:\")\n",
        "    print(\"1. Use current scenario WAD (defend_the_center.cfg with vizdoom assets)\")\n",
        "    print(\"2. Use original Doom WAD from Google Drive (ViZDoomWADs folder with defend_the_center.cfg)\")\n",
        "    wad_choice = input(\"Enter your choice (1 or 2): \")\n",
        "    logger.info(f\"WAD Choice: {wad_choice}\")\n",
        "    return wad_choice\n",
        "\n",
        "def setup_scenario(wad_choice, logger):\n",
        "    global SCENARIO_NAME\n",
        "    SCENARIO_NAME = \"defend_the_center.cfg\"\n",
        "\n",
        "    if wad_choice == \"1\":\n",
        "        try:\n",
        "            import vizdoom\n",
        "            vizdoom_path = os.path.dirname(vizdoom.__file__)\n",
        "            SCENARIO_PATH = os.path.join(vizdoom_path, \"scenarios\", SCENARIO_NAME)\n",
        "            wad_path = None\n",
        "            logger.info(f\"Using default scenario path: {SCENARIO_PATH}\")\n",
        "            return SCENARIO_PATH, wad_path\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading default scenario: {e}\")\n",
        "            # Fallback: Try to use a path relative to the current file\n",
        "            SCENARIO_PATH = os.path.join(\"scenarios\", SCENARIO_NAME)\n",
        "            logger.warning(f\"Trying fallback scenario path: {SCENARIO_PATH}\")\n",
        "            return SCENARIO_PATH, None\n",
        "\n",
        "    elif wad_choice == \"2\":\n",
        "        wad_files = glob.glob(os.path.join(DRIVE_WAD_DIR, \"*.wad\"))\n",
        "        if not wad_files:\n",
        "            logger.warning(\"No WAD files found in ViZDoomWADs. Using default scenario.\")\n",
        "            return setup_scenario(\"1\", logger)\n",
        "        print(\"Available WAD files in ViZDoomWADs:\")\n",
        "        for i, file in enumerate(wad_files):\n",
        "            print(f\"{i+1}. {os.path.basename(file)}\")\n",
        "        wad_file_choice = input(\"Enter the number of the WAD file to use: \")\n",
        "        try:\n",
        "            wad_file_choice = int(wad_file_choice)\n",
        "            if 1 <= wad_file_choice <= len(wad_files):\n",
        "                wad_path = wad_files[wad_file_choice - 1]\n",
        "                local_wad_path = os.path.join(LOCAL_WAD_DIR, os.path.basename(wad_path))\n",
        "                if not os.path.exists(local_wad_path):\n",
        "                    print(f\"Copying {os.path.basename(wad_path)} from Google Drive to local...\")\n",
        "                    try:\n",
        "                        shutil.copy(wad_path, local_wad_path)\n",
        "                        logger.info(f\"Copied {os.path.basename(wad_path)} from Google Drive to local.\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"Error copying wad file to local: {e}\")\n",
        "                        return setup_scenario(\"1\", logger)\n",
        "                else:\n",
        "                    print(f\"{os.path.basename(wad_path)} already exists locally. Using local copy.\")\n",
        "                    logger.info(f\"{os.path.basename(wad_path)} already exists locally.\")\n",
        "                wad_path = local_wad_path\n",
        "                import vizdoom\n",
        "                vizdoom_path = os.path.dirname(vizdoom.__file__)\n",
        "                SCENARIO_PATH = os.path.join(vizdoom_path, \"scenarios\", SCENARIO_NAME)\n",
        "                logger.info(f\"Using WAD file: {wad_path}, scenario path: {SCENARIO_PATH}\")\n",
        "                return SCENARIO_PATH, wad_path\n",
        "            else:\n",
        "                logger.warning(\"Invalid WAD file choice. Using default scenario.\")\n",
        "                return setup_scenario(\"1\", logger)\n",
        "        except ValueError:\n",
        "            logger.warning(\"Invalid input. Using default scenario.\")\n",
        "            return setup_scenario(\"1\", logger)\n",
        "    else:\n",
        "        logger.warning(\"Invalid choice. Using default scenario.\")\n",
        "        return setup_scenario(\"1\", logger)\n",
        "\n",
        "# --- DQN ---\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "        self.fc1 = nn.Linear(self.get_conv_output(input_shape), 512)\n",
        "        self.fc2 = nn.Linear(512, num_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def get_conv_output(self, shape):\n",
        "        o = self.conv1(torch.zeros(1, *shape))\n",
        "        o = self.conv2(o)\n",
        "        o = self.conv3(o)\n",
        "        return int(np.prod(o.size()))\n",
        "\n",
        "class NoisyLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, std_init=0.4):\n",
        "        super(NoisyLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.std_init = std_init\n",
        "\n",
        "        self.weight_mu = nn.Parameter(torch.empty(out_features, in_features))\n",
        "        self.weight_sigma = nn.Parameter(torch.empty(out_features, in_features))\n",
        "        self.register_buffer('weight_epsilon', torch.empty(out_features, in_features))\n",
        "\n",
        "        self.bias_mu = nn.Parameter(torch.empty(out_features))\n",
        "        self.bias_sigma = nn.Parameter(torch.empty(out_features))\n",
        "        self.register_buffer('bias_epsilon', torch.empty(out_features))\n",
        "\n",
        "        self.reset_parameters()\n",
        "        self.reset_noise()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        mu_range = 1 / math.sqrt(self.in_features)\n",
        "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
        "        self.weight_sigma.data.fill_(self.std_init / math.sqrt(self.in_features))\n",
        "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
        "        self.bias_sigma.data.fill_(self.std_init / math.sqrt(self.out_features))\n",
        "\n",
        "    def reset_noise(self):\n",
        "        epsilon_in = self._scale_noise(self.in_features)\n",
        "        epsilon_out = self._scale_noise(self.out_features)\n",
        "        self.weight_epsilon.copy_(epsilon_out.outer(epsilon_in))\n",
        "        self.bias_epsilon.copy_(epsilon_out)\n",
        "\n",
        "    def _scale_noise(self, size):\n",
        "        x = torch.randn(size)\n",
        "        return x.sign().mul_(x.abs().sqrt_())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.linear(x,\n",
        "                       self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
        "                       self.bias_mu + self.bias_sigma * self.bias_epsilon)\n",
        "\n",
        "class DuelingDQN(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions, use_noisy=True):\n",
        "        super(DuelingDQN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "\n",
        "        conv_out_size = self._get_conv_output(input_shape)\n",
        "\n",
        "        # Value stream\n",
        "        if use_noisy:\n",
        "            self.value_fc = NoisyLinear(conv_out_size, 512)\n",
        "            self.value = NoisyLinear(512, 1)\n",
        "        else:\n",
        "            self.value_fc = nn.Linear(conv_out_size, 512)\n",
        "            self.value = nn.Linear(512, 1)\n",
        "\n",
        "        # Advantage stream\n",
        "        if use_noisy:\n",
        "            self.advantage_fc = NoisyLinear(conv_out_size, 512)\n",
        "            self.advantage = NoisyLinear(512, num_actions)\n",
        "        else:\n",
        "            self.advantage_fc = nn.Linear(conv_out_size, 512)\n",
        "            self.advantage = nn.Linear(512, num_actions)\n",
        "\n",
        "        self.use_noisy = use_noisy\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def _get_conv_output(self, shape):\n",
        "        o = torch.zeros(1, *shape)\n",
        "        o = F.relu(self.conv1(o))\n",
        "        o = F.relu(self.conv2(o))\n",
        "        o = F.relu(self.conv3(o))\n",
        "        return int(np.prod(o.size()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        value = F.relu(self.value_fc(x))\n",
        "        value = self.value(value)\n",
        "\n",
        "        advantage = F.relu(self.advantage_fc(x))\n",
        "        advantage = self.advantage(advantage)\n",
        "\n",
        "        return value + advantage - advantage.mean(dim=1, keepdim=True)\n",
        "\n",
        "    def reset_noise(self):\n",
        "        if self.use_noisy:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, NoisyLinear):\n",
        "                    m.reset_noise()\n",
        "\n",
        "# --- Prioritized Experience Replay Memory ---\n",
        "class PrioritizedReplayMemory:\n",
        "    def __init__(self, capacity, alpha=0.6, beta_start=0.4, beta_frames=100000):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "        self.priorities = np.zeros(capacity, dtype=np.float32)\n",
        "        self.alpha = alpha\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_frames = beta_frames\n",
        "        self.frame = 0\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        max_priority = self.priorities.max() if self.memory else 1.0\n",
        "\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "\n",
        "        self.memory[self.position] = (state, action, reward, next_state, done)\n",
        "        self.priorities[self.position] = max_priority\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        priorities = self.priorities[:len(self.memory)]\n",
        "        probabilities = priorities**self.alpha\n",
        "        probabilities /= probabilities.sum()\n",
        "\n",
        "        indices = np.random.choice(len(self.memory), batch_size, p=probabilities)\n",
        "        samples = [self.memory[idx] for idx in indices]\n",
        "\n",
        "        beta = min(1.0, self.beta_start + (self.frame * (1 - self.beta_start) / self.beta_frames))\n",
        "        weights = (len(self.memory) * probabilities[indices])**(-beta)\n",
        "        weights /= weights.max()\n",
        "        self.frame += 1\n",
        "\n",
        "        return samples, indices, weights\n",
        "\n",
        "    def update_priorities(self, indices, td_errors):\n",
        "        self.priorities[indices] = np.abs(td_errors) + 1e-6\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "# --- N-step Buffer ---\n",
        "class NStepBuffer:\n",
        "    def __init__(self, n_step):\n",
        "        self.n_step = n_step\n",
        "        self.buffer = []\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def get(self):\n",
        "        if len(self.buffer) < self.n_step:\n",
        "            return None\n",
        "\n",
        "        n_step_state, n_step_action, n_step_reward, n_step_next_state, n_step_done = self.buffer[0]\n",
        "        for i in range(1, self.n_step):\n",
        "            state, action, reward, next_state, done = self.buffer[i]\n",
        "            n_step_reward += reward * GAMMA**i\n",
        "            n_step_next_state = next_state\n",
        "            n_step_done = done or n_step_done\n",
        "\n",
        "        self.buffer = self.buffer[1:]\n",
        "        return n_step_state, n_step_action, n_step_reward, n_step_next_state, n_step_done\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "# --- DQNAgent ---\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_shape, num_actions, learning_rate, gamma, epsilon_start, epsilon_end, epsilon_decay, memory_capacity, batch_size, tau, n_step, grad_clip_norm, epsilon_decay_rate_step):\n",
        "        self.state_shape = state_shape\n",
        "        self.num_actions = num_actions\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon_start\n",
        "        self.epsilon_start = epsilon_start\n",
        "        self.epsilon_end = epsilon_end\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.batch_size = batch_size\n",
        "        self.tau = tau\n",
        "        self.grad_clip_norm = grad_clip_norm\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.policy_net = DQN(state_shape, num_actions).to(self.device)\n",
        "        self.target_net = DQN(state_shape, num_actions).to(self.device)\n",
        "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "        self.target_net.eval()\n",
        "\n",
        "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=learning_rate)\n",
        "        self.memory = PrioritizedReplayMemory(memory_capacity)\n",
        "        self.n_step_buffer = NStepBuffer(n_step)\n",
        "        self.epsilon_decay_rate_step = epsilon_decay_rate_step\n",
        "        self.training_step = 0\n",
        "        self.best_avg_reward = float('-inf')\n",
        "        self.best_model_state = None\n",
        "\n",
        "    def select_action(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(self.num_actions)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                state = torch.tensor(state, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
        "                q_values = self.policy_net(state)\n",
        "                return q_values.argmax(dim=1).item()\n",
        "\n",
        "    def update_epsilon(self):\n",
        "        self.epsilon = max(self.epsilon_end, self.epsilon_start * (self.epsilon_decay ** (self.training_step / self.epsilon_decay_rate_step)))\n",
        "\n",
        "    def learn(self):\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return None, None, None\n",
        "        self.training_step += 1\n",
        "        samples, indices, weights = self.memory.sample(self.batch_size)\n",
        "        batch = tuple(zip(*samples))\n",
        "\n",
        "        state_batch = torch.tensor(np.array(batch[0]), dtype=torch.float32, device=self.device)\n",
        "        action_batch = torch.tensor(batch[1], dtype=torch.long, device=self.device).unsqueeze(1)\n",
        "        reward_batch = torch.tensor(batch[2], dtype=torch.float32, device=self.device).unsqueeze(1)\n",
        "        next_state_batch = torch.tensor(np.array(batch[3]), dtype=torch.float32, device=self.device)\n",
        "        done_batch = torch.tensor(batch[4], dtype=torch.float32, device=self.device).unsqueeze(1)\n",
        "        weights = torch.tensor(weights, dtype=torch.float32, device=self.device).unsqueeze(1)\n",
        "\n",
        "        q_values = self.policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            next_q_values_online = self.policy_net(next_state_batch)\n",
        "            next_actions = next_q_values_online.argmax(dim=1).unsqueeze(1)\n",
        "            next_q_values_target = self.target_net(next_state_batch).gather(1, next_actions)\n",
        "            expected_q_values = reward_batch + self.gamma * next_q_values_target * (1 - done_batch)\n",
        "\n",
        "        td_errors = expected_q_values - q_values\n",
        "        loss = (weights * F.smooth_l1_loss(q_values, expected_q_values, reduction='none')).mean()\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), self.grad_clip_norm)\n",
        "        self.optimizer.step()\n",
        "\n",
        "        self.memory.update_priorities(indices, td_errors.detach().cpu().numpy().squeeze())\n",
        "        return loss.item(), q_values.mean().item(), torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), self.grad_clip_norm).item()\n",
        "\n",
        "    def update_target_network(self):\n",
        "        for target_param, local_param in zip(self.target_net.parameters(), self.policy_net.parameters()):\n",
        "            target_param.data.copy_(self.tau * local_param.data + (1.0 - self.tau) * target_param.data)\n",
        "\n",
        "    def save_model(self, model_path):\n",
        "        torch.save({\n",
        "            'policy_net_state_dict': self.policy_net.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "        }, model_path)\n",
        "\n",
        "    def load_model(self, model_path):\n",
        "        checkpoint = torch.load(model_path, map_location=self.device)\n",
        "        self.policy_net.load_state_dict(checkpoint['policy_net_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "\n",
        "def scan_for_models(agent, model_dir, logger):\n",
        "    model_files = glob.glob(os.path.join(model_dir, \"*.pth\"))\n",
        "\n",
        "    if not model_files:\n",
        "        logger.info(\"No existing models found. Creating new model...\")\n",
        "        return agent  # Return the existing agent instead of creating new one\n",
        "\n",
        "    print(\"Available models:\")\n",
        "    for i, file in enumerate(model_files):\n",
        "        print(f\"{i+1}. {os.path.basename(file)}\")\n",
        "    print(f\"{len(model_files)+1}. Create new model\")\n",
        "\n",
        "    choice = input(\"Enter your choice: \")\n",
        "    try:\n",
        "        choice = int(choice)\n",
        "        if choice in range(1, len(model_files) + 2):\n",
        "            if choice <= len(model_files):\n",
        "                model_path = model_files[choice - 1]\n",
        "                try:\n",
        "                    agent.load_model(model_path)\n",
        "                    logger.info(f\"Model loaded from {model_path}\")\n",
        "                    return agent\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error loading model: {e}\")\n",
        "                    return agent  # Return existing agent on error\n",
        "            else:\n",
        "                logger.info(\"Creating new model...\")\n",
        "                return agent  # Return existing agent for new model\n",
        "        else:\n",
        "            logger.warning(\"Invalid choice. Using existing model.\")\n",
        "            return agent\n",
        "    except ValueError:\n",
        "        logger.warning(\"Invalid input. Using existing model.\")\n",
        "        return agent\n",
        "\n",
        "def setup_vizdoom(scenario_path, wad_path=None, logger=None):\n",
        "    try:\n",
        "        from vizdoom import DoomGame, ScreenFormat, ScreenResolution, Mode\n",
        "        game = DoomGame()\n",
        "\n",
        "        if scenario_path:\n",
        "            game.load_config(scenario_path)\n",
        "        else:\n",
        "            raise ValueError(\"Scenario path is not defined.\")\n",
        "\n",
        "        if wad_path:\n",
        "            game.set_doom_game_path(wad_path)\n",
        "        game.set_window_visible(False)\n",
        "        game.set_screen_format(ScreenFormat.RGB24)\n",
        "        game.set_screen_resolution(ScreenResolution.RES_320X240)\n",
        "\n",
        "        if RECORD_LMP:\n",
        "            game.set_mode(Mode.PLAYER)\n",
        "            os.makedirs(LMP_DIR, exist_ok=True)\n",
        "\n",
        "        game.init()\n",
        "        num_actions = game.get_available_buttons_size()\n",
        "        actions = np.identity(num_actions, dtype=int).tolist()\n",
        "\n",
        "        screen_height, screen_width = game.get_screen_height(), game.get_screen_width()\n",
        "        channels = game.get_screen_channels()\n",
        "        state_shape = (STACK_SIZE * channels, 84, 84)\n",
        "        logger.info(\"ViZDoom initialized successfully.\")\n",
        "        return game, actions, state_shape\n",
        "    except Exception as e:\n",
        "        if logger:\n",
        "            logger.error(f\"Error during ViZDoom setup: {e}\")\n",
        "        print(f\"Error during ViZDoom setup: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "# --- Video Writer ---\n",
        "def setup_video_writer(video_path, video_fps, logger=None):\n",
        "    if RECORD_VIDEO:\n",
        "      try:\n",
        "        video_writer = imageio.get_writer(video_path, fps=video_fps)\n",
        "        logger.info(f\"Video Writer set up at: {video_path}\")\n",
        "        return video_writer\n",
        "      except Exception as e:\n",
        "          logger.error(f\"Error during video writer setup: {e}\")\n",
        "          return None\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "# --- TensorBoard Setup ---\n",
        "def setup_tensorboard(log_dir, logger=None):\n",
        "    now = datetime.now()\n",
        "    dt_string = now.strftime(\"%Y%m%d%H%M\")\n",
        "    log_dir = os.path.join(log_dir, f\"{dt_string}_experiment\")\n",
        "    if logger:\n",
        "      logger.info(f\"TensorBoard logging to: {log_dir}\")\n",
        "    return SummaryWriter(log_dir=log_dir)\n",
        "\n",
        "# --- Frame Stacking ---\n",
        "def preprocess_frame(frames):\n",
        "    if len(frames) == 0:\n",
        "        return []\n",
        "    processed_frames = []\n",
        "    for frame in frames:\n",
        "        if len(frame.shape) == 3 and frame.shape[0] == 3:\n",
        "            frame = np.mean(frame, axis=0)\n",
        "        frame = frame.astype(np.float32) / 255.0\n",
        "        frame = cv2.resize(frame, (84, 84), interpolation=cv2.INTER_AREA)\n",
        "        if len(frame.shape) == 3:\n",
        "            frame = frame.transpose(2, 0, 1)\n",
        "        else:\n",
        "            frame = np.expand_dims(frame, axis=0)\n",
        "        processed_frames.append(frame)\n",
        "    return processed_frames\n",
        "\n",
        "def create_stacked_state(state_buffer):\n",
        "    processed_frames = preprocess_frame(state_buffer)\n",
        "    if any(f is None for f in processed_frames) or not all(f.shape == processed_frames[0].shape for f in processed_frames):\n",
        "        print(\"Error: Inconsistent or None frames in processed_frames\")\n",
        "        return None\n",
        "    stacked_state = np.concatenate(processed_frames, axis=0)\n",
        "    return stacked_state\n",
        "\n",
        "def get_game_state_info(game):\n",
        "    game_state = game.get_state()\n",
        "    if game_state is not None:\n",
        "        damage_taken = game_state.game_variables[0]\n",
        "        damage_inflicted = game_state.game_variables[1]\n",
        "        return damage_taken, damage_inflicted\n",
        "    else:\n",
        "        return 0, 0\n",
        "\n",
        "def run_episode(agent, game, actions, episode, frame_skip, lmp_dir, record_video, video_writer, stack_size, state_shape, logger, episode_metrics_df):\n",
        "    if RECORD_LMP:\n",
        "        lmp_file_path = os.path.join(lmp_dir, f\"episode_{episode + 1}.lmp\")\n",
        "        game.new_episode(lmp_file_path)\n",
        "    else:\n",
        "        game.new_episode()\n",
        "\n",
        "    game_state = game.get_state()\n",
        "    if game_state is None or game_state.screen_buffer is None:\n",
        "        logger.error(f\"Skipping episode {episode+1} due to invalid game state.\")\n",
        "        return None, 0, 0, 0, 0, 0, None\n",
        "\n",
        "    state_buffer = [game_state.screen_buffer] * stack_size\n",
        "    state = create_stacked_state(state_buffer)\n",
        "    if state is None:\n",
        "        logger.error(f\"Skipping episode {episode + 1} due to state initialization error.\")\n",
        "        return None, 0, 0, 0, 0, 0, None\n",
        "\n",
        "    total_reward = 0\n",
        "    step_count = 0\n",
        "    episode_start_time = time.time()\n",
        "    damage_taken = 0\n",
        "    damage_inflicted = 0\n",
        "    action_counts = Counter()\n",
        "    inference_times = []\n",
        "    loss, avg_q_value, grad_norm = None, None, None\n",
        "\n",
        "    while not game.is_episode_finished():\n",
        "        inference_start_time = time.time()\n",
        "\n",
        "        action_index = agent.select_action(state)\n",
        "\n",
        "        inference_end_time = time.time()\n",
        "        inference_times.append(inference_end_time - inference_start_time)\n",
        "\n",
        "        action = actions[action_index]\n",
        "        action_counts[action_index] += 1\n",
        "\n",
        "        reward = game.make_action(action, frame_skip)\n",
        "        done = game.is_episode_finished()\n",
        "\n",
        "        if not done:\n",
        "            game_state = game.get_state()\n",
        "            if game_state and game_state.screen_buffer is not None:\n",
        "                next_frame = game_state.screen_buffer\n",
        "                state_buffer.pop(0)\n",
        "                state_buffer.append(next_frame)\n",
        "                next_state = create_stacked_state(state_buffer)\n",
        "\n",
        "                if next_state is None:\n",
        "                    logger.error(f\"Error: next_state is None in episode {episode + 1} at step {step_count + 1}.\")\n",
        "                    break\n",
        "                damage_taken_step, damage_inflicted_step = get_game_state_info(game)\n",
        "                damage_taken += damage_taken_step\n",
        "                damage_inflicted += damage_inflicted_step\n",
        "            else:\n",
        "                logger.error(f\"Error: Invalid state in episode {episode+1}, step {step_count+1}.\")\n",
        "                next_state = np.zeros(state_shape)\n",
        "                break\n",
        "        else:\n",
        "            next_state = np.zeros(state_shape)\n",
        "\n",
        "        agent.n_step_buffer.push(state, action_index, reward, next_state, done)\n",
        "\n",
        "        n_step_experience = agent.n_step_buffer.get()\n",
        "        if n_step_experience:\n",
        "            n_step_state, n_step_action, n_step_reward, n_step_next_state, n_step_done = n_step_experience\n",
        "            agent.memory.push(n_step_state, n_step_action, n_step_reward, n_step_next_state, n_step_done)\n",
        "\n",
        "        loss_step, avg_q_value_step, grad_norm_step = agent.learn()\n",
        "        if loss_step is not None:\n",
        "            loss = loss_step\n",
        "            avg_q_value = avg_q_value_step\n",
        "            grad_norm = grad_norm_step\n",
        "\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "        step_count += 1\n",
        "\n",
        "        if record_video and not done:\n",
        "            most_recent_frame = state_buffer[-1]\n",
        "            try:\n",
        "                video_writer.append_data(most_recent_frame)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error appending frame to video: {e}\")\n",
        "                break\n",
        "\n",
        "    episode_survival_time = time.time() - episode_start_time\n",
        "    total_actions = sum(action_counts.values())\n",
        "    if total_actions > 0:\n",
        "        action_diversity = sum(count / total_actions for count in action_counts.values()) / len(actions)\n",
        "    else:\n",
        "        action_diversity = 0\n",
        "\n",
        "    avg_inference_time = np.mean(inference_times) if inference_times else 0\n",
        "\n",
        "    if total_reward is not None:\n",
        "        new_row = {\n",
        "            'episode': episode + 1,\n",
        "            'reward': total_reward,\n",
        "            'steps': step_count,\n",
        "            'survival_time': episode_survival_time,\n",
        "            'damage_taken': damage_taken,\n",
        "            'damage_inflicted': damage_inflicted,\n",
        "            'action_diversity': action_diversity,\n",
        "            'avg_inference_time': avg_inference_time,\n",
        "            'loss': loss if loss is not None else np.nan,\n",
        "            'avg_q_value': avg_q_value if avg_q_value is not None else np.nan,\n",
        "            'grad_norm': grad_norm if grad_norm is not None else np.nan\n",
        "        }\n",
        "        return total_reward, step_count, episode_survival_time, damage_taken, damage_inflicted, action_diversity, avg_inference_time, new_row\n",
        "    else:\n",
        "        return None, 0, 0, 0, 0, 0, 0, None\n",
        "\n",
        "# --- Validation ---\n",
        "def validate_model(agent, game, actions, state_shape, stack_size, num_episodes, logger):\n",
        "    \"\"\"Validates the model by running a number of episodes and calculating the mean reward.\"\"\"\n",
        "    total_rewards = []\n",
        "    for episode in range(num_episodes):\n",
        "        total_reward, _, _, _, _, _, _, _ = run_episode(agent, game, actions, episode, FRAME_SKIP_RECORDING, None, False, None, stack_size, state_shape, logger, pd.DataFrame())\n",
        "        if total_reward is not None:\n",
        "            total_rewards.append(total_reward)\n",
        "    return np.mean(total_rewards) if total_rewards else float('-inf')\n",
        "\n",
        "def best_model_callback(agent, episode_rewards, logger, model_dir, best_model_smoothing_window):\n",
        "    \"\"\"Callback to save the best model based on a smoothed average reward.\"\"\"\n",
        "    if len(episode_rewards) >= best_model_smoothing_window:\n",
        "        avg_reward = np.mean(episode_rewards[-best_model_smoothing_window:])\n",
        "    else:\n",
        "        avg_reward = np.mean(episode_rewards) if episode_rewards else float('-inf')\n",
        "    if avg_reward > agent.best_avg_reward:\n",
        "        agent.best_avg_reward = avg_reward\n",
        "        agent.best_model_state = deepcopy(agent.policy_net.state_dict())\n",
        "        model_filename = f\"best_dqn_model.pth\"\n",
        "        model_path = os.path.join(model_dir, model_filename)\n",
        "        agent.save_model(model_path)\n",
        "        logger.info(f\"Best model saved to {model_path} with reward: {agent.best_avg_reward}\")\n",
        "\n",
        "# --- Save metrics to CSV ---\n",
        "def save_metrics(episode_rewards, episode_lengths, episode_survival_times,\n",
        "                 episode_damage_taken, episode_damage_inflicted, logger, episode_metrics_df, training_time,\n",
        "                 ram_usage_list, gpu_memory_usage_list, action_diversity_list):\n",
        "    base_metrics = pd.DataFrame({\n",
        "        'episode': range(1, len(episode_rewards) + 1),\n",
        "        'reward': episode_rewards,\n",
        "        'steps': episode_lengths,\n",
        "        'epsilon': [EPSILON_START * (EPSILON_DECAY ** (i / EPSILON_DECAY_RATE_STEP)) for i in range(len(episode_rewards))],\n",
        "        'training_time': training_time,\n",
        "        'survival_time': episode_survival_times,\n",
        "        'damage_taken': episode_damage_taken,\n",
        "        'damage_inflicted': episode_damage_inflicted,\n",
        "        'ram_usage': ram_usage_list,\n",
        "        'gpu_memory_usage': gpu_memory_usage_list,\n",
        "        'action_diversity': action_diversity_list\n",
        "    })\n",
        "\n",
        "    # Merge with episode metrics if they exist\n",
        "    if not episode_metrics_df.empty:\n",
        "        metrics_df = pd.merge(base_metrics, episode_metrics_df, on='episode', how='left')\n",
        "    else:\n",
        "        metrics_df = base_metrics\n",
        "\n",
        "    # Add hyperparameters\n",
        "    metrics_df['model_save_freq'] = MODEL_SAVE_FREQ\n",
        "    metrics_df['batch_size'] = BATCH_SIZE\n",
        "    metrics_df['memory_capacity'] = MEMORY_CAPACITY\n",
        "    metrics_df['learning_rate'] = LEARNING_RATE\n",
        "    metrics_df['tau'] = TAU\n",
        "    metrics_df['n_step'] = N_STEP\n",
        "\n",
        "    # Save to file\n",
        "    now = datetime.now()\n",
        "    dt_string = now.strftime(\"%Y%m%d%H%M\")\n",
        "    metrics_filename = f\"{dt_string}_training_metrics.csv\"\n",
        "    metrics_path = os.path.join(DRIVE_MODEL_DIR, metrics_filename)\n",
        "    metrics_df.to_csv(metrics_path, index=False)\n",
        "    logger.info(f\"Training metrics saved to {metrics_path}\")\n",
        "\n",
        "# --- Main Training Loop ---\n",
        "def cleanup_resources():\n",
        "    # Clear memory\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "def close_writers(video_writer=None, tensorboard_writer=None):\n",
        "    try:\n",
        "        if video_writer:\n",
        "            video_writer.close()  # Use close() instead of release() for imageio writer\n",
        "        if tensorboard_writer:\n",
        "            tensorboard_writer.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Error closing writers: {e}\")\n",
        "\n",
        "def validate_input(value, param_type, min_val, max_val, default):\n",
        "    try:\n",
        "        if param_type == \"float\":\n",
        "            val = float(value)\n",
        "        else:\n",
        "            val = int(value)\n",
        "\n",
        "        if min_val <= val <= max_val:\n",
        "            return val\n",
        "        print(f\"Value out of range ({min_val}-{max_val}). Using default: {default}\")\n",
        "        return default\n",
        "    except ValueError:\n",
        "        print(f\"Invalid input. Using default: {default}\")\n",
        "        return default\n",
        "\n",
        "def get_hyperparameters():\n",
        "    params = {\n",
        "        \"learning_rate\": {\"default\": 0.00025, \"type\": \"float\", \"min\": 0, \"max\": 1,\n",
        "                         \"desc\": \"Step size for optimizer (0-1)\"},\n",
        "        \"batch_size\": {\"default\": 64, \"type\": \"int\", \"min\": 32, \"max\": 512,\n",
        "                      \"desc\": \"Batch size for training (32-512)\"},\n",
        "        \"memory_capacity\": {\"default\": 50000, \"type\": \"int\", \"min\": 10000, \"max\": 1000000,\n",
        "                          \"desc\": \"Max experiences in memory (10k-1M)\"},\n",
        "        \"gamma\": {\"default\": 0.99, \"type\": \"float\", \"min\": 0, \"max\": 1,\n",
        "                 \"desc\": \"Discount factor (0-1)\"},\n",
        "        \"tau\": {\"default\": 0.005, \"type\": \"float\", \"min\": 0, \"max\": 1,\n",
        "                \"desc\": \"Target network update rate (0-1)\"},\n",
        "        \"epsilon_start\": {\"default\": 1.0, \"type\": \"float\", \"min\": 0, \"max\": 1,\n",
        "                         \"desc\": \"Initial exploration rate (0-1)\"},\n",
        "        \"epsilon_end\": {\"default\": 0.05, \"type\": \"float\", \"min\": 0, \"max\": 1,\n",
        "                       \"desc\": \"Final exploration rate (0-1)\"},\n",
        "        \"epsilon_decay\": {\"default\": 0.995, \"type\": \"float\", \"min\": 0, \"max\": 1,\n",
        "                         \"desc\": \"Exploration decay rate (0-1)\"},\n",
        "        \"epsilon_decay_rate_step\": {\"default\": 5000, \"type\": \"int\", \"min\": 1000, \"max\": 100000,\n",
        "                                   \"desc\": \"Steps for epsilon decay (1k-100k)\"},\n",
        "        \"n_step\": {\"default\": 3, \"type\": \"int\", \"min\": 1, \"max\": 10,\n",
        "                   \"desc\": \"Steps for n-step learning (1-10)\"},\n",
        "        \"grad_clip_norm\": {\"default\": 1.0, \"type\": \"float\", \"min\": 0, \"max\": 10,\n",
        "                          \"desc\": \"Gradient clipping norm (0-10)\"},\n",
        "        \"frame_stack_size\": {\"default\": 4, \"type\": \"int\", \"min\": 2, \"max\": 4,\n",
        "                            \"desc\": \"Number of stacked frames (2-4)\"}\n",
        "    }\n",
        "\n",
        "    print(\"\\nHyperparameter Configuration Menu\")\n",
        "    print(\"=================================\")\n",
        "\n",
        "    for param_name, param_info in params.items():\n",
        "        print(f\"\\n{param_name}: {param_info['desc']}\")\n",
        "        print(f\"Default: {param_info['default']}\")\n",
        "        user_input = input(f\"Enter value (or press Enter for default): \").strip()\n",
        "\n",
        "        if user_input:\n",
        "            params[param_name][\"value\"] = validate_input(\n",
        "                user_input,\n",
        "                param_info[\"type\"],\n",
        "                param_info[\"min\"],\n",
        "                param_info[\"max\"],\n",
        "                param_info[\"default\"]\n",
        "            )\n",
        "        else:\n",
        "            params[param_name][\"value\"] = param_info[\"default\"]\n",
        "\n",
        "    return params\n",
        "\n",
        "def get_run_mode():\n",
        "    print(\"\\nSelect Run Mode:\")\n",
        "    print(\"1. Quick Run (Default settings)\")\n",
        "    print(\"2. Custom Run (Configure all settings)\")\n",
        "    while True:\n",
        "        try:\n",
        "            choice = int(input(\"Enter your choice (1 or 2): \").strip())\n",
        "            if choice in [1, 2]:\n",
        "                return choice\n",
        "            print(\"Please enter 1 or 2\")\n",
        "        except ValueError:\n",
        "            print(\"Please enter a valid number\")\n",
        "\n",
        "def quick_run_setup(logger):\n",
        "    \"\"\"Quick run setup with model selection\"\"\"\n",
        "    try:\n",
        "        # First handle model choice\n",
        "        print(\"\\nModel Selection:\")\n",
        "        print(\"1. Create new model\")\n",
        "        print(\"2. Load existing model\")\n",
        "        while True:\n",
        "            model_choice = input(\"Enter choice (1 or 2): \").strip()\n",
        "            if model_choice in ['1', '2']:\n",
        "                break\n",
        "            print(\"Please enter 1 or 2\")\n",
        "\n",
        "        episodes = int(input(\"Enter number of episodes (default=1): \").strip() or \"1\")\n",
        "        save_freq = int(input(\"Enter model save frequency (default=1): \").strip() or \"1\")\n",
        "\n",
        "        return {\n",
        "            \"num_episodes\": max(1, episodes),\n",
        "            \"model_save_freq\": max(1, save_freq),\n",
        "            \"record_video\": False,\n",
        "            \"frame_skip\": FRAME_SKIP_TRAINING,\n",
        "            \"create_new_model\": model_choice == '1',\n",
        "            **default_config  # Include other defaults\n",
        "        }\n",
        "    except ValueError as e:\n",
        "        logger.error(f\"Invalid input: {e}\")\n",
        "        return default_config\n",
        "\n",
        "def get_run_config(logger):\n",
        "    \"\"\"Get run configuration with proper logger\"\"\"\n",
        "    config = {\n",
        "        \"scenario_path\": None,\n",
        "        \"wad_path\": None,\n",
        "        \"drive_model_dir\": DRIVE_MODEL_DIR,\n",
        "    }\n",
        "\n",
        "    # Get WAD setup\n",
        "    wad_choice = get_wad_choice(logger)\n",
        "    config[\"scenario_path\"], config[\"wad_path\"] = setup_scenario(wad_choice, logger)\n",
        "\n",
        "    # Get run mode\n",
        "    run_mode = get_run_mode()\n",
        "\n",
        "    if run_mode == 1:  # Quick Run\n",
        "        quick_config = quick_run_setup(logger)\n",
        "        config.update(quick_config)\n",
        "    else:  # Custom Run\n",
        "        params = get_hyperparameters()\n",
        "        config.update({\n",
        "            **params,\n",
        "            \"create_new_model\": True  # Custom runs always create new model\n",
        "        })\n",
        "\n",
        "    return config\n",
        "\n",
        "def main():\n",
        "    # Initialize logger first\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
        "    log_dir = \"logs\"\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    logger = setup_logger(log_dir, timestamp)\n",
        "\n",
        "    game = None\n",
        "    video_writer = None\n",
        "    tensorboard_writer = None\n",
        "\n",
        "    try:\n",
        "        # Get configuration with logger\n",
        "        config = get_run_config(logger)\n",
        "\n",
        "        if not config[\"scenario_path\"]:\n",
        "            logger.error(\"No scenario path specified\")\n",
        "            return\n",
        "\n",
        "        # Initialize game\n",
        "        game, actions, state_shape = setup_vizdoom(\n",
        "            config[\"scenario_path\"],\n",
        "            config[\"wad_path\"],\n",
        "            logger\n",
        "        )\n",
        "\n",
        "        if not all([game, actions, state_shape]):\n",
        "            logger.error(\"Failed to initialize ViZDoom environment\")\n",
        "            return\n",
        "\n",
        "        # Initialize agent\n",
        "        agent = DQNAgent(\n",
        "            state_shape=state_shape,\n",
        "            num_actions=len(actions),\n",
        "            learning_rate=config.get(\"learning_rate\", LEARNING_RATE),\n",
        "            gamma=config.get(\"gamma\", GAMMA),\n",
        "            epsilon_start=config.get(\"epsilon_start\", EPSILON_START),\n",
        "            epsilon_end=config.get(\"epsilon_end\", EPSILON_END),\n",
        "            epsilon_decay=config.get(\"epsilon_decay\", EPSILON_DECAY),\n",
        "            memory_capacity=config.get(\"memory_capacity\", MEMORY_CAPACITY),\n",
        "            batch_size=config.get(\"batch_size\", BATCH_SIZE),\n",
        "            tau=config.get(\"tau\", TAU),\n",
        "            n_step=config.get(\"n_step\", N_STEP),\n",
        "            grad_clip_norm=config.get(\"grad_clip_norm\", GRAD_CLIP_NORM),\n",
        "            epsilon_decay_rate_step=config.get(\"epsilon_decay_rate_step\", EPSILON_DECAY_RATE_STEP)\n",
        "        )\n",
        "\n",
        "        # Load existing model if requested\n",
        "        if not config.get(\"create_new_model\", True):\n",
        "            agent = scan_for_models(agent, config[\"drive_model_dir\"], logger)\n",
        "\n",
        "        # Setup writers\n",
        "        if config[\"record_video\"]:\n",
        "            video_writer = setup_video_writer(VIDEO_PATH, VIDEO_FPS, logger)\n",
        "        tensorboard_writer = setup_tensorboard(log_dir, logger)\n",
        "\n",
        "        # Initialize metrics tracking\n",
        "        metrics_data = []  # Store episode metrics as dictionaries\n",
        "        episode_rewards = []\n",
        "        episode_lengths = []\n",
        "        episode_survival_times = []\n",
        "        episode_damage_taken = []\n",
        "        episode_damage_inflicted = []\n",
        "        ram_usage_list = []\n",
        "        gpu_memory_usage_list = []\n",
        "        action_diversity_list = []\n",
        "        training_start_time = time.time()\n",
        "\n",
        "        # Training loop\n",
        "        for episode in range(config[\"num_episodes\"]):\n",
        "            try:\n",
        "                # Run episode\n",
        "                metrics = run_episode(\n",
        "                    agent=agent,\n",
        "                    game=game,\n",
        "                    actions=actions,\n",
        "                    episode=episode,\n",
        "                    frame_skip=config[\"frame_skip\"],\n",
        "                    lmp_dir=LMP_DIR if RECORD_LMP else None,\n",
        "                    record_video=config[\"record_video\"],\n",
        "                    video_writer=video_writer,\n",
        "                    stack_size=STACK_SIZE,\n",
        "                    state_shape=state_shape,\n",
        "                    logger=logger,\n",
        "                    episode_metrics_df=None  # Remove DataFrame dependency\n",
        "                )\n",
        "\n",
        "                if metrics:\n",
        "                    reward, steps, survival_time, damage_taken, damage_inflicted, action_diversity, inference_time, new_row = metrics\n",
        "\n",
        "                    # Update metrics lists\n",
        "                    episode_rewards.append(reward)\n",
        "                    episode_lengths.append(steps)\n",
        "                    episode_survival_times.append(survival_time)\n",
        "                    episode_damage_taken.append(damage_taken)\n",
        "                    episode_damage_inflicted.append(damage_inflicted)\n",
        "                    action_diversity_list.append(action_diversity)\n",
        "\n",
        "                    # Resource monitoring\n",
        "                    ram_usage = psutil.Process().memory_info().rss / 1024 / 1024  # MB\n",
        "                    ram_usage_list.append(ram_usage)\n",
        "\n",
        "                    if torch.cuda.is_available():\n",
        "                        gpu_memory = torch.cuda.memory_allocated() / 1024 / 1024  # MB\n",
        "                        gpu_memory_usage_list.append(gpu_memory)\n",
        "                    else:\n",
        "                        gpu_memory_usage_list.append(0)\n",
        "\n",
        "                    # Store metrics dictionary\n",
        "                    if new_row:\n",
        "                        metrics_data.append(new_row)\n",
        "\n",
        "                # Save model if needed\n",
        "                if (episode + 1) % config[\"model_save_freq\"] == 0:\n",
        "                    model_path = os.path.join(config[\"drive_model_dir\"], f\"model_episode_{episode+1}.pth\")\n",
        "                    agent.save_model(model_path)\n",
        "                    logger.info(f\"Model saved at episode {episode+1}\")\n",
        "\n",
        "                # Save best model if enabled\n",
        "                if USE_BEST_MODEL_CALLBACK:\n",
        "                    best_model_callback(agent, episode_rewards, logger, config[\"drive_model_dir\"], BEST_MODEL_SMOOTHING_WINDOW)\n",
        "\n",
        "                # Log progress\n",
        "                logger.info(f\"Episode {episode+1}/{config['num_episodes']}: \"\n",
        "                          f\"Reward={reward:.2f}, Steps={steps}, \"\n",
        "                          f\"Epsilon={agent.epsilon:.3f}\")\n",
        "\n",
        "                # Cleanup after episode\n",
        "                cleanup_resources()\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error in episode {episode}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Create final metrics DataFrame\n",
        "        episode_metrics_df = pd.DataFrame(metrics_data)\n",
        "\n",
        "        # Save final metrics\n",
        "        training_time = time.time() - training_start_time\n",
        "        save_metrics(\n",
        "            episode_rewards, episode_lengths, episode_survival_times,\n",
        "            episode_damage_taken, episode_damage_inflicted, logger,\n",
        "            episode_metrics_df, training_time, ram_usage_list,\n",
        "            gpu_memory_usage_list, action_diversity_list\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during training: {e}\")\n",
        "        raise e\n",
        "\n",
        "    finally:\n",
        "        # Cleanup\n",
        "        try:\n",
        "            close_writers(video_writer, tensorboard_writer)\n",
        "            if game:\n",
        "                game.close()\n",
        "            cleanup_resources()\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during cleanup: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "{\n",
        "  \"type\": \"setting\",\n",
        "  \"settings\": {\n",
        "    \"python.logging.level\": \"INFO\"\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "JT3GRHPXe8T1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4750c20-13cd-4db7-a686-8c234d467949"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan  7 14:10:45 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P0              29W /  70W |    225MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2kS2QyklGd5l"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1uKx3KG8j0dj3l7O8Dh3DzTRowzB7D0wg",
      "authorship_tag": "ABX9TyNMl73xVCsQnAVYTZmhckLF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}