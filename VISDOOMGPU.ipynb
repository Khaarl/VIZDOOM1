{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khaarl/VIZDOOM1/blob/03/VISDOOMGPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "+-----------------------------------------------------------------------------+\n",
        "| |       |\\                                           -~ /     \\  /          |\n",
        "|~~__     | \\                                         | \\/       /\\          /|\n",
        "|    --   |  \\                                        | / \\    /    \\     /   |\n",
        "|      |~_|   \\                                   \\___|/    \\/         /      |\n",
        "|--__  |   -- |\\________________________________/~~\\~~|    /  \\     /     \\   |\n",
        "|   |~~--__  |~_|____|____|____|____|____|____|/ /  \\/|\\ /      \\/          \\/|\n",
        "|   |      |~--_|__|____|____|____|____|____|_/ /|    |/ \\    /   \\       /   |\n",
        "|___|______|__|_||____|____|____|____|____|__[]/_|----|    \\/       \\  /      |\n",
        "|  \\mmmm :   | _|___|____|____|____|____|____|___|  /\\|   /  \\      /  \\      |\n",
        "|      B :_--~~ |_|____|____|____|____|____|____|  |  |\\/      \\ /        \\   |\n",
        "|  __--P :  |  /                                /  /  | \\     /  \\          /\\|\n",
        "|~~  |   :  | /                                 ~~~   |  \\  /      \\      /   |\n",
        "|    |      |/                        .-.             |  /\\          \\  /     |\n",
        "|    |      /                        |   |            |/   \\          /\\      |\n",
        "|    |     /                        |     |            -_   \\       /    \\    |\n",
        "+-----------------------------------------------------------------------------+\n",
        "|          |  /|  |   |  2  3  4  | /~~~~~\\ |       /|    |_| ....  ......... |\n",
        "|          |  ~|~ | % |           | | ~J~ | |       ~|~ % |_| ....  ......... |\n",
        "|   AMMO   |  HEALTH  |  5  6  7  |  \\===/  |    ARMOR    |#| ....  ......... |\n",
        "+-----------------------------------------------------------------------------+"
      ],
      "metadata": {
        "id": "uKWem7K5d_mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7852EWnX1Zc",
        "outputId": "0d9de8ed-4d26-4495-d42f-ea8fe7912ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.82)] [1 InRelease 3,626 B/3\r0% [Waiting for headers] [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)]\r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [61.1 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,631 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,226 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,513 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,552 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,852 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,517 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,652 kB]\n",
            "Fetched 18.4 MB in 9s (2,017 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "libjpeg-dev is already the newest version (8c-2ubuntu10).\n",
            "libjpeg-dev set to manually installed.\n",
            "libpng-dev is already the newest version (1.6.37-3build5).\n",
            "libboost-all-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.11).\n",
            "libpython3-dev is already the newest version (3.10.6-1~22.04.1).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-2ubuntu9.2).\n",
            "zlib1g-dev set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  gir1.2-ibus-1.0 libblkid-dev libblkid1 libdbus-1-dev libdecor-0-dev libdrm-dev libegl-dev\n",
            "  libegl1-mesa-dev libffi-dev libgbm-dev libgl-dev libgles-dev libgles1 libglib2.0-dev\n",
            "  libglib2.0-dev-bin libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev libglx-dev\n",
            "  libibus-1.0-5 libibus-1.0-dev libice-dev libmount-dev libmount1 libopengl-dev libpciaccess-dev\n",
            "  libpulse-dev libpulse-mainloop-glib0 libselinux1-dev libsepol-dev libsm-dev libsndio-dev\n",
            "  libudev-dev libudev1 libwayland-bin libwayland-dev libxcursor-dev libxfixes-dev libxi-dev\n",
            "  libxinerama-dev libxkbcommon-dev libxrandr-dev libxt-dev libxv-dev libxxf86vm-dev\n",
            "Suggested packages:\n",
            "  libgirepository1.0-dev libglib2.0-doc libgdk-pixbuf2.0-bin | libgdk-pixbuf2.0-dev libxml2-utils\n",
            "  libice-doc cryptsetup-bin libsm-doc libwayland-doc libxt-doc\n",
            "The following NEW packages will be installed:\n",
            "  gir1.2-ibus-1.0 libblkid-dev libdbus-1-dev libdecor-0-dev libdrm-dev libegl-dev libegl1-mesa-dev\n",
            "  libffi-dev libgbm-dev libgl-dev libgles-dev libgles1 libglib2.0-dev libglib2.0-dev-bin\n",
            "  libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev libglx-dev libibus-1.0-5\n",
            "  libibus-1.0-dev libice-dev libmount-dev libopengl-dev libpciaccess-dev libpulse-dev\n",
            "  libpulse-mainloop-glib0 libsdl2-dev libselinux1-dev libsepol-dev libsm-dev libsndio-dev\n",
            "  libudev-dev libwayland-bin libwayland-dev libxcursor-dev libxfixes-dev libxi-dev libxinerama-dev\n",
            "  libxkbcommon-dev libxrandr-dev libxt-dev libxv-dev libxxf86vm-dev\n",
            "The following packages will be upgraded:\n",
            "  libblkid1 libmount1 libudev1\n",
            "3 upgraded, 44 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 7,357 kB of archives.\n",
            "After this operation, 40.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libblkid1 amd64 2.37.2-4ubuntu3.4 [103 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmount1 amd64 2.37.2-4ubuntu3.4 [122 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.12 [78.2 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libibus-1.0-5 amd64 1.5.26-4 [183 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 gir1.2-ibus-1.0 amd64 1.5.26-4 [88.3 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdbus-1-dev amd64 1.12.20-2ubuntu4.1 [188 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libwayland-bin amd64 1.20.0-1ubuntu0.1 [20.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libffi-dev amd64 3.4.2-4 [63.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libwayland-dev amd64 1.20.0-1ubuntu0.1 [69.5 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdecor-0-dev amd64 0.1.0-3build1 [5,544 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpciaccess-dev amd64 0.16-3 [21.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdrm-dev amd64 2.4.113-2~ubuntu0.22.04.1 [292 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libegl1-mesa-dev amd64 23.2.1-1ubuntu3.1~22.04.3 [11.1 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgbm-dev amd64 23.2.1-1ubuntu3.1~22.04.3 [9,542 B]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-dev-bin amd64 2.72.4-0ubuntu2.4 [117 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libblkid-dev amd64 2.37.2-4ubuntu3.4 [185 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsepol-dev amd64 3.3-1build1 [378 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 libselinux1-dev amd64 3.3-1build2 [158 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmount-dev amd64 2.37.2-4ubuntu3.4 [14.5 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-dev amd64 2.72.4-0ubuntu2.4 [1,743 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libibus-1.0-dev amd64 1.5.26-4 [185 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpulse-mainloop-glib0 amd64 1:15.99.1+dfsg1-1ubuntu2.2 [12.4 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpulse-dev amd64 1:15.99.1+dfsg1-1ubuntu2.2 [75.6 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libsndio-dev amd64 1.8.1-1.1 [17.8 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev-dev amd64 249.11-0ubuntu3.12 [20.7 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfixes-dev amd64 1:6.0.0-1 [12.2 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcursor-dev amd64 1:1.2.0-2build4 [28.2 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxi-dev amd64 2:1.8-1build1 [193 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxinerama-dev amd64 2:1.1.4-3 [8,104 B]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-dev amd64 1.4.0-1 [54.9 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxrandr-dev amd64 2:1.5.2-1build1 [26.7 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxv-dev amd64 2:1.0.11-1build2 [33.4 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86vm-dev amd64 1:1.1.4-1build3 [13.9 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsdl2-dev amd64 2.0.20+dfsg-2ubuntu1.22.04.1 [1,767 kB]\n",
            "Fetched 7,357 kB in 2s (4,455 kB/s)\n",
            "Extracting templates from packages: 100%\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../libblkid1_2.37.2-4ubuntu3.4_amd64.deb ...\n",
            "Unpacking libblkid1:amd64 (2.37.2-4ubuntu3.4) over (2.37.2-4ubuntu3) ...\n",
            "Setting up libblkid1:amd64 (2.37.2-4ubuntu3.4) ...\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../libmount1_2.37.2-4ubuntu3.4_amd64.deb ...\n",
            "Unpacking libmount1:amd64 (2.37.2-4ubuntu3.4) over (2.37.2-4ubuntu3) ...\n",
            "Setting up libmount1:amd64 (2.37.2-4ubuntu3.4) ...\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.12) over (249.11-0ubuntu3.10) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package libibus-1.0-5:amd64.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libibus-1.0-5_1.5.26-4_amd64.deb ...\n",
            "Unpacking libibus-1.0-5:amd64 (1.5.26-4) ...\n",
            "Selecting previously unselected package gir1.2-ibus-1.0:amd64.\n",
            "Preparing to unpack .../01-gir1.2-ibus-1.0_1.5.26-4_amd64.deb ...\n",
            "Unpacking gir1.2-ibus-1.0:amd64 (1.5.26-4) ...\n",
            "Selecting previously unselected package libdbus-1-dev:amd64.\n",
            "Preparing to unpack .../02-libdbus-1-dev_1.12.20-2ubuntu4.1_amd64.deb ...\n",
            "Unpacking libdbus-1-dev:amd64 (1.12.20-2ubuntu4.1) ...\n",
            "Selecting previously unselected package libwayland-bin.\n",
            "Preparing to unpack .../03-libwayland-bin_1.20.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libwayland-bin (1.20.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libffi-dev:amd64.\n",
            "Preparing to unpack .../04-libffi-dev_3.4.2-4_amd64.deb ...\n",
            "Unpacking libffi-dev:amd64 (3.4.2-4) ...\n",
            "Selecting previously unselected package libwayland-dev:amd64.\n",
            "Preparing to unpack .../05-libwayland-dev_1.20.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libwayland-dev:amd64 (1.20.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libdecor-0-dev:amd64.\n",
            "Preparing to unpack .../06-libdecor-0-dev_0.1.0-3build1_amd64.deb ...\n",
            "Unpacking libdecor-0-dev:amd64 (0.1.0-3build1) ...\n",
            "Selecting previously unselected package libpciaccess-dev:amd64.\n",
            "Preparing to unpack .../07-libpciaccess-dev_0.16-3_amd64.deb ...\n",
            "Unpacking libpciaccess-dev:amd64 (0.16-3) ...\n",
            "Selecting previously unselected package libdrm-dev:amd64.\n",
            "Preparing to unpack .../08-libdrm-dev_2.4.113-2~ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libdrm-dev:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "Preparing to unpack .../09-libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../10-libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl-dev:amd64.\n",
            "Preparing to unpack .../11-libegl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
            "Preparing to unpack .../12-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../13-libgles1_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../14-libgles-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../15-libopengl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../16-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../17-libegl1-mesa-dev_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking libegl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Selecting previously unselected package libgbm-dev:amd64.\n",
            "Preparing to unpack .../18-libgbm-dev_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking libgbm-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Selecting previously unselected package libglib2.0-dev-bin.\n",
            "Preparing to unpack .../19-libglib2.0-dev-bin_2.72.4-0ubuntu2.4_amd64.deb ...\n",
            "Unpacking libglib2.0-dev-bin (2.72.4-0ubuntu2.4) ...\n",
            "Selecting previously unselected package libblkid-dev:amd64.\n",
            "Preparing to unpack .../20-libblkid-dev_2.37.2-4ubuntu3.4_amd64.deb ...\n",
            "Unpacking libblkid-dev:amd64 (2.37.2-4ubuntu3.4) ...\n",
            "Selecting previously unselected package libsepol-dev:amd64.\n",
            "Preparing to unpack .../21-libsepol-dev_3.3-1build1_amd64.deb ...\n",
            "Unpacking libsepol-dev:amd64 (3.3-1build1) ...\n",
            "Selecting previously unselected package libselinux1-dev:amd64.\n",
            "Preparing to unpack .../22-libselinux1-dev_3.3-1build2_amd64.deb ...\n",
            "Unpacking libselinux1-dev:amd64 (3.3-1build2) ...\n",
            "Selecting previously unselected package libmount-dev:amd64.\n",
            "Preparing to unpack .../23-libmount-dev_2.37.2-4ubuntu3.4_amd64.deb ...\n",
            "Unpacking libmount-dev:amd64 (2.37.2-4ubuntu3.4) ...\n",
            "Selecting previously unselected package libglib2.0-dev:amd64.\n",
            "Preparing to unpack .../24-libglib2.0-dev_2.72.4-0ubuntu2.4_amd64.deb ...\n",
            "Unpacking libglib2.0-dev:amd64 (2.72.4-0ubuntu2.4) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../25-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglu1-mesa-dev:amd64.\n",
            "Preparing to unpack .../26-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libibus-1.0-dev:amd64.\n",
            "Preparing to unpack .../27-libibus-1.0-dev_1.5.26-4_amd64.deb ...\n",
            "Unpacking libibus-1.0-dev:amd64 (1.5.26-4) ...\n",
            "Selecting previously unselected package libice-dev:amd64.\n",
            "Preparing to unpack .../28-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n",
            "Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Selecting previously unselected package libpulse-mainloop-glib0:amd64.\n",
            "Preparing to unpack .../29-libpulse-mainloop-glib0_1%3a15.99.1+dfsg1-1ubuntu2.2_amd64.deb ...\n",
            "Unpacking libpulse-mainloop-glib0:amd64 (1:15.99.1+dfsg1-1ubuntu2.2) ...\n",
            "Selecting previously unselected package libpulse-dev:amd64.\n",
            "Preparing to unpack .../30-libpulse-dev_1%3a15.99.1+dfsg1-1ubuntu2.2_amd64.deb ...\n",
            "Unpacking libpulse-dev:amd64 (1:15.99.1+dfsg1-1ubuntu2.2) ...\n",
            "Selecting previously unselected package libsndio-dev:amd64.\n",
            "Preparing to unpack .../31-libsndio-dev_1.8.1-1.1_amd64.deb ...\n",
            "Unpacking libsndio-dev:amd64 (1.8.1-1.1) ...\n",
            "Selecting previously unselected package libudev-dev:amd64.\n",
            "Preparing to unpack .../32-libudev-dev_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking libudev-dev:amd64 (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package libxfixes-dev:amd64.\n",
            "Preparing to unpack .../33-libxfixes-dev_1%3a6.0.0-1_amd64.deb ...\n",
            "Unpacking libxfixes-dev:amd64 (1:6.0.0-1) ...\n",
            "Selecting previously unselected package libxcursor-dev:amd64.\n",
            "Preparing to unpack .../34-libxcursor-dev_1%3a1.2.0-2build4_amd64.deb ...\n",
            "Unpacking libxcursor-dev:amd64 (1:1.2.0-2build4) ...\n",
            "Selecting previously unselected package libxi-dev:amd64.\n",
            "Preparing to unpack .../35-libxi-dev_2%3a1.8-1build1_amd64.deb ...\n",
            "Unpacking libxi-dev:amd64 (2:1.8-1build1) ...\n",
            "Selecting previously unselected package libxinerama-dev:amd64.\n",
            "Preparing to unpack .../36-libxinerama-dev_2%3a1.1.4-3_amd64.deb ...\n",
            "Unpacking libxinerama-dev:amd64 (2:1.1.4-3) ...\n",
            "Selecting previously unselected package libxkbcommon-dev:amd64.\n",
            "Preparing to unpack .../37-libxkbcommon-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libxrandr-dev:amd64.\n",
            "Preparing to unpack .../38-libxrandr-dev_2%3a1.5.2-1build1_amd64.deb ...\n",
            "Unpacking libxrandr-dev:amd64 (2:1.5.2-1build1) ...\n",
            "Selecting previously unselected package libsm-dev:amd64.\n",
            "Preparing to unpack .../39-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n",
            "Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../40-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package libxv-dev:amd64.\n",
            "Preparing to unpack .../41-libxv-dev_2%3a1.0.11-1build2_amd64.deb ...\n",
            "Unpacking libxv-dev:amd64 (2:1.0.11-1build2) ...\n",
            "Selecting previously unselected package libxxf86vm-dev:amd64.\n",
            "Preparing to unpack .../42-libxxf86vm-dev_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libxxf86vm-dev:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libsdl2-dev:amd64.\n",
            "Preparing to unpack .../43-libsdl2-dev_2.0.20+dfsg-2ubuntu1.22.04.1_amd64.deb ...\n",
            "Unpacking libsdl2-dev:amd64 (2.0.20+dfsg-2ubuntu1.22.04.1) ...\n",
            "Setting up libglib2.0-dev-bin (2.72.4-0ubuntu2.4) ...\n",
            "Setting up libblkid-dev:amd64 (2.37.2-4ubuntu3.4) ...\n",
            "Setting up libsndio-dev:amd64 (1.8.1-1.1) ...\n",
            "Setting up libpciaccess-dev:amd64 (0.16-3) ...\n",
            "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Setting up libxxf86vm-dev:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libxkbcommon-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libibus-1.0-5:amd64 (1.5.26-4) ...\n",
            "Setting up libffi-dev:amd64 (3.4.2-4) ...\n",
            "Setting up libgbm-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up libxfixes-dev:amd64 (1:6.0.0-1) ...\n",
            "Setting up libxv-dev:amd64 (2:1.0.11-1build2) ...\n",
            "Setting up libwayland-bin (1.20.0-1ubuntu0.1) ...\n",
            "Setting up libxrandr-dev:amd64 (2:1.5.2-1build1) ...\n",
            "Setting up libdbus-1-dev:amd64 (1.12.20-2ubuntu4.1) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up libpulse-mainloop-glib0:amd64 (1:15.99.1+dfsg1-1ubuntu2.2) ...\n",
            "Setting up libgles1:amd64 (1.4.0-1) ...\n",
            "Setting up libudev-dev:amd64 (249.11-0ubuntu3.12) ...\n",
            "Setting up libxinerama-dev:amd64 (2:1.1.4-3) ...\n",
            "Setting up libsepol-dev:amd64 (3.3-1build1) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libxi-dev:amd64 (2:1.8-1build1) ...\n",
            "Setting up gir1.2-ibus-1.0:amd64 (1.5.26-4) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libdrm-dev:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
            "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libselinux1-dev:amd64 (3.3-1build2) ...\n",
            "Setting up libxcursor-dev:amd64 (1:1.2.0-2build4) ...\n",
            "Setting up libwayland-dev:amd64 (1.20.0-1ubuntu0.1) ...\n",
            "Setting up libdecor-0-dev:amd64 (0.1.0-3build1) ...\n",
            "Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libmount-dev:amd64 (2.37.2-4ubuntu3.4) ...\n",
            "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglib2.0-dev:amd64 (2.72.4-0ubuntu2.4) ...\n",
            "Setting up libegl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.4) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Setting up libibus-1.0-dev:amd64 (1.5.26-4) ...\n",
            "Setting up libpulse-dev:amd64 (1:15.99.1+dfsg1-1ubuntu2.2) ...\n",
            "Setting up libsdl2-dev:amd64 (2.0.20+dfsg-2ubuntu1.22.04.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# --- Setup ---\n",
        "!apt-get update -y\n",
        "!apt-get install -y build-essential cmake git libboost-all-dev libsdl2-dev libjpeg-dev libpng-dev zlib1g-dev libpython3-dev\n",
        "\n",
        "!apt-get install ffmpeg\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "# Use Mesa for software rendering (CPU-based)\n",
        "os.environ['LIBGL_ALWAYS_SOFTWARE'] = '1'\n",
        "\n",
        "# Set XDG_RUNTIME_DIR to avoid other SDL issues\n",
        "os.environ['XDG_RUNTIME_DIR'] = '/tmp'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtIdiASZX82K",
        "outputId": "3ddccf70-8860-4a9c-aabc-5ea43e76b184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping vizdoom as it is not installed.\u001b[0m\u001b[33m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libboost-python-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "libboost-python-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Cloning into 'ViZDoom'...\n",
            "remote: Enumerating objects: 18734, done.\u001b[K\n",
            "remote: Counting objects: 100% (567/567), done.\u001b[K\n",
            "remote: Compressing objects: 100% (198/198), done.\u001b[K\n",
            "remote: Total 18734 (delta 469), reused 369 (delta 369), pack-reused 18167 (from 5)\u001b[K\n",
            "Receiving objects: 100% (18734/18734), 59.90 MiB | 25.04 MiB/s, done.\n",
            "Resolving deltas: 100% (11722/11722), done.\n",
            "/content/ViZDoom\n",
            "\u001b[33mCMake Warning:\n",
            "  Ignoring extra path from command line:\n",
            "\n",
            "   \"..\"\n",
            "\n",
            "\u001b[0m\n",
            "\u001b[0mCMake Error: The source directory \"/content\" does not appear to contain CMakeLists.txt.\n",
            "Specify --help for usage, or press the help button on the CMake GUI.\u001b[0m\n",
            "make: *** No rule to make target 'install'.  Stop.\n",
            "/content\n",
            "Collecting vizdoom\n",
            "  Downloading vizdoom-1.2.4-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vizdoom) (1.26.4)\n",
            "Collecting gymnasium>=0.28.0 (from vizdoom)\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from vizdoom) (2.6.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->vizdoom) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->vizdoom) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium>=0.28.0->vizdoom)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Downloading vizdoom-1.2.4-cp310-cp310-manylinux_2_28_x86_64.whl (28.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.1/28.1 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium, vizdoom\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0 vizdoom-1.2.4\n"
          ]
        }
      ],
      "source": [
        "# --- Install ViZDoom from source (for proper linking) ---\n",
        "!pip uninstall -y vizdoom\n",
        "!apt-get install -y libboost-python-dev\n",
        "!git clone https://github.com/mwydmuch/ViZDoom.git\n",
        "%cd ViZDoom\n",
        "!mkdir build && cd build\n",
        "!cmake .. -DBUILD_PYTHON=ON -DCMAKE_INSTALL_PREFIX=/usr/local\n",
        "!make -j$(nproc) install\n",
        "%cd /content\n",
        "!pip install vizdoom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zK1wHVDGX-os",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f82622-22eb-43e7-9ee6-3de8ac8ab7db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Enable video recording? (y/n, default=n): y\n",
            "Enter frame skip rate (1-10, default=1): \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-06 23:24:30,492 - INFO - Google Drive directories created successfully.\n",
            "INFO:__main__:Google Drive directories created successfully.\n",
            "2025-01-06 23:24:30,497 - INFO - Skipped existing: simpler_basic.wad\n",
            "INFO:__main__:Skipped existing: simpler_basic.wad\n",
            "2025-01-06 23:24:30,502 - INFO - Skipped existing: rocket_basic.wad\n",
            "INFO:__main__:Skipped existing: rocket_basic.wad\n",
            "2025-01-06 23:24:30,506 - INFO - Skipped existing: predict_position.wad\n",
            "INFO:__main__:Skipped existing: predict_position.wad\n",
            "2025-01-06 23:24:30,509 - INFO - Skipped existing: defend_the_line.wad\n",
            "INFO:__main__:Skipped existing: defend_the_line.wad\n",
            "2025-01-06 23:24:30,512 - INFO - Skipped existing: cig.wad\n",
            "INFO:__main__:Skipped existing: cig.wad\n",
            "2025-01-06 23:24:30,514 - INFO - Skipped existing: deathmatch.wad\n",
            "INFO:__main__:Skipped existing: deathmatch.wad\n",
            "2025-01-06 23:24:30,516 - INFO - Skipped existing: cig_with_unknown.wad\n",
            "INFO:__main__:Skipped existing: cig_with_unknown.wad\n",
            "2025-01-06 23:24:30,518 - INFO - Skipped existing: my_way_home.wad\n",
            "INFO:__main__:Skipped existing: my_way_home.wad\n",
            "2025-01-06 23:24:30,520 - INFO - Skipped existing: deadly_corridor.wad\n",
            "INFO:__main__:Skipped existing: deadly_corridor.wad\n",
            "2025-01-06 23:24:30,522 - INFO - Skipped existing: multi_duel.wad\n",
            "INFO:__main__:Skipped existing: multi_duel.wad\n",
            "2025-01-06 23:24:30,524 - INFO - Skipped existing: defend_the_center.wad\n",
            "INFO:__main__:Skipped existing: defend_the_center.wad\n",
            "2025-01-06 23:24:30,527 - INFO - Skipped existing: health_gathering_supreme.wad\n",
            "INFO:__main__:Skipped existing: health_gathering_supreme.wad\n",
            "2025-01-06 23:24:30,529 - INFO - Skipped existing: take_cover.wad\n",
            "INFO:__main__:Skipped existing: take_cover.wad\n",
            "2025-01-06 23:24:30,531 - INFO - Skipped existing: health_gathering.wad\n",
            "INFO:__main__:Skipped existing: health_gathering.wad\n",
            "2025-01-06 23:24:30,533 - INFO - Skipped existing: multi_deathmatch.wad\n",
            "INFO:__main__:Skipped existing: multi_deathmatch.wad\n",
            "2025-01-06 23:24:30,535 - INFO - Skipped existing: basic.wad\n",
            "INFO:__main__:Skipped existing: basic.wad\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose a WAD file to use:\n",
            "1. Use current scenario WAD (defend_the_center.cfg with vizdoom assets)\n",
            "2. Use original Doom WAD from Google Drive (ViZDoomWADs folder with defend_the_center.cfg)\n",
            "Enter your choice (1 or 2): \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-06 23:24:32,588 - INFO - WAD Choice: \n",
            "INFO:__main__:WAD Choice: \n",
            "2025-01-06 23:24:32,591 - WARNING - Invalid choice. Using default scenario.\n",
            "WARNING:__main__:Invalid choice. Using default scenario.\n",
            "2025-01-06 23:24:32,593 - INFO - Using default scenario path: /usr/local/lib/python3.10/dist-packages/vizdoom/scenarios/defend_the_center.cfg\n",
            "INFO:__main__:Using default scenario path: /usr/local/lib/python3.10/dist-packages/vizdoom/scenarios/defend_the_center.cfg\n",
            "2025-01-06 23:24:33,010 - INFO - ViZDoom initialized successfully.\n",
            "INFO:__main__:ViZDoom initialized successfully.\n",
            "2025-01-06 23:24:33,015 - INFO - TensorBoard logging to: runs/202501062324_experiment\n",
            "INFO:__main__:TensorBoard logging to: runs/202501062324_experiment\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter Configuration Menu\n",
            "=================================\n",
            "\n",
            "learning_rate: Step size for optimizer (0-1)\n",
            "Default: 0.00025\n",
            "Enter value (or press Enter for default): \n",
            "\n",
            "batch_size: Batch size for training (32-512)\n",
            "Default: 64\n",
            "Enter value (or press Enter for default): \n",
            "\n",
            "memory_capacity: Max experiences in memory (10k-1M)\n",
            "Default: 50000\n",
            "Enter value (or press Enter for default): \n",
            "\n",
            "gamma: Discount factor (0-1)\n",
            "Default: 0.99\n",
            "Enter value (or press Enter for default): \n",
            "\n",
            "tau: Target network update rate (0-1)\n",
            "Default: 0.005\n",
            "Enter value (or press Enter for default): \n",
            "\n",
            "epsilon_start: Initial exploration rate (0-1)\n",
            "Default: 1.0\n",
            "Enter value (or press Enter for default): \n",
            "\n",
            "epsilon_end: Final exploration rate (0-1)\n",
            "Default: 0.05\n",
            "Enter value (or press Enter for default): \n",
            "\n",
            "epsilon_decay: Exploration decay rate (0-1)\n",
            "Default: 0.995\n",
            "Enter value (or press Enter for default): \n",
            "\n",
            "epsilon_decay_rate_step: Steps for epsilon decay (1k-100k)\n",
            "Default: 5000\n",
            "Enter value (or press Enter for default): \n",
            "\n",
            "n_step: Steps for n-step learning (1-10)\n",
            "Default: 3\n",
            "Enter value (or press Enter for default): \n",
            "\n",
            "grad_clip_norm: Gradient clipping norm (0-10)\n",
            "Default: 1.0\n",
            "Enter value (or press Enter for default): \n",
            "\n",
            "frame_stack_size: Number of stacked frames (2-4)\n",
            "Default: 4\n",
            "Enter value (or press Enter for default): \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-06 23:24:52,530 - INFO - Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062324_game_recording.mp4\n",
            "INFO:__main__:Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062324_game_recording.mp4\n",
            "<ipython-input-7-1b8ab9d2b91b>:302: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast() if self.use_amp else nullcontext():\n",
            "<ipython-input-7-1b8ab9d2b91b>:1221: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  episode_metrics_df = pd.concat([\n",
            "2025-01-06 23:25:00,077 - INFO - Model saved to /content/drive/My Drive/ViZDoomModels/dqn_model_episode_0.pth\n",
            "INFO:__main__:Model saved to /content/drive/My Drive/ViZDoomModels/dqn_model_episode_0.pth\n",
            "2025-01-06 23:25:00,085 - INFO - Episode 1: Reward = -1.00, Steps = 234, Damage Taken = 4722.0, Damage Inflicted = 19604.0\n",
            "INFO:__main__:Episode 1: Reward = -1.00, Steps = 234, Damage Taken = 4722.0, Damage Inflicted = 19604.0\n",
            "2025-01-06 23:25:00,386 - INFO - Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062324_game_recording.mp4\n",
            "INFO:__main__:Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062324_game_recording.mp4\n",
            "2025-01-06 23:25:00,393 - INFO - Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062325_game_recording.mp4\n",
            "INFO:__main__:Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062325_game_recording.mp4\n",
            "2025-01-06 23:25:21,612 - INFO - Episode 2: Reward = 2.00, Steps = 450, Damage Taken = 6577.0, Damage Inflicted = 31820.0\n",
            "INFO:__main__:Episode 2: Reward = 2.00, Steps = 450, Damage Taken = 6577.0, Damage Inflicted = 31820.0\n",
            "2025-01-06 23:25:22,088 - INFO - Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062325_game_recording.mp4\n",
            "INFO:__main__:Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062325_game_recording.mp4\n",
            "2025-01-06 23:25:22,093 - INFO - Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062325_game_recording.mp4\n",
            "INFO:__main__:Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062325_game_recording.mp4\n",
            "2025-01-06 23:25:38,788 - INFO - Episode 3: Reward = 0.00, Steps = 376, Damage Taken = 6037.0, Damage Inflicted = 27468.0\n",
            "INFO:__main__:Episode 3: Reward = 0.00, Steps = 376, Damage Taken = 6037.0, Damage Inflicted = 27468.0\n",
            "2025-01-06 23:25:39,036 - INFO - Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062325_game_recording.mp4\n",
            "INFO:__main__:Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062325_game_recording.mp4\n",
            "2025-01-06 23:25:39,042 - INFO - Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062325_game_recording.mp4\n",
            "INFO:__main__:Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062325_game_recording.mp4\n",
            "2025-01-06 23:25:49,613 - INFO - Episode 4: Reward = 0.00, Steps = 248, Damage Taken = 4890.0, Damage Inflicted = 18684.0\n",
            "INFO:__main__:Episode 4: Reward = 0.00, Steps = 248, Damage Taken = 4890.0, Damage Inflicted = 18684.0\n",
            "2025-01-06 23:25:50,012 - INFO - Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062325_game_recording.mp4\n",
            "INFO:__main__:Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062325_game_recording.mp4\n",
            "2025-01-06 23:25:50,017 - INFO - Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062325_game_recording.mp4\n",
            "INFO:__main__:Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062325_game_recording.mp4\n",
            "2025-01-06 23:26:07,833 - INFO - Episode 5: Reward = -1.00, Steps = 394, Damage Taken = 6011.0, Damage Inflicted = 27740.0\n",
            "INFO:__main__:Episode 5: Reward = -1.00, Steps = 394, Damage Taken = 6011.0, Damage Inflicted = 27740.0\n",
            "2025-01-06 23:26:08,087 - INFO - Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062325_game_recording.mp4\n",
            "INFO:__main__:Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062325_game_recording.mp4\n",
            "2025-01-06 23:26:08,094 - INFO - Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062326_game_recording.mp4\n",
            "INFO:__main__:Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062326_game_recording.mp4\n",
            "2025-01-06 23:26:23,054 - INFO - Episode 6: Reward = 1.00, Steps = 328, Damage Taken = 5798.0, Damage Inflicted = 23828.0\n",
            "INFO:__main__:Episode 6: Reward = 1.00, Steps = 328, Damage Taken = 5798.0, Damage Inflicted = 23828.0\n",
            "2025-01-06 23:26:23,422 - INFO - Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062326_game_recording.mp4\n",
            "INFO:__main__:Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062326_game_recording.mp4\n",
            "2025-01-06 23:26:23,429 - INFO - Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062326_game_recording.mp4\n",
            "INFO:__main__:Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062326_game_recording.mp4\n",
            "2025-01-06 23:26:34,131 - INFO - Episode 7: Reward = 0.00, Steps = 248, Damage Taken = 4913.0, Damage Inflicted = 20044.0\n",
            "INFO:__main__:Episode 7: Reward = 0.00, Steps = 248, Damage Taken = 4913.0, Damage Inflicted = 20044.0\n",
            "2025-01-06 23:26:34,530 - INFO - Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062326_game_recording.mp4\n",
            "INFO:__main__:Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062326_game_recording.mp4\n",
            "2025-01-06 23:26:34,539 - INFO - Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062326_game_recording.mp4\n",
            "INFO:__main__:Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062326_game_recording.mp4\n",
            "2025-01-06 23:26:53,971 - INFO - Episode 8: Reward = 0.00, Steps = 402, Damage Taken = 5940.0, Damage Inflicted = 26004.0\n",
            "INFO:__main__:Episode 8: Reward = 0.00, Steps = 402, Damage Taken = 5940.0, Damage Inflicted = 26004.0\n",
            "2025-01-06 23:26:54,188 - INFO - Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062326_game_recording.mp4\n",
            "INFO:__main__:Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062326_game_recording.mp4\n",
            "2025-01-06 23:26:54,193 - INFO - Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062326_game_recording.mp4\n",
            "INFO:__main__:Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062326_game_recording.mp4\n",
            "2025-01-06 23:27:06,847 - INFO - Episode 9: Reward = 0.00, Steps = 268, Damage Taken = 4887.0, Damage Inflicted = 20724.0\n",
            "INFO:__main__:Episode 9: Reward = 0.00, Steps = 268, Damage Taken = 4887.0, Damage Inflicted = 20724.0\n",
            "2025-01-06 23:27:07,261 - INFO - Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062326_game_recording.mp4\n",
            "INFO:__main__:Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062326_game_recording.mp4\n",
            "2025-01-06 23:27:07,266 - INFO - Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062327_game_recording.mp4\n",
            "INFO:__main__:Video recording started: /content/drive/My Drive/ViZDoomRecordings/2501062327_game_recording.mp4\n",
            "2025-01-06 23:27:23,096 - INFO - Episode 10: Reward = 1.00, Steps = 338, Damage Taken = 5620.0, Damage Inflicted = 24116.0\n",
            "INFO:__main__:Episode 10: Reward = 1.00, Steps = 338, Damage Taken = 5620.0, Damage Inflicted = 24116.0\n",
            "2025-01-06 23:27:23,540 - INFO - Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062327_game_recording.mp4\n",
            "INFO:__main__:Video saved: /content/drive/My Drive/ViZDoomRecordings/2501062327_game_recording.mp4\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import yaml\n",
        "import shutil\n",
        "import time\n",
        "import random\n",
        "import logging\n",
        "import glob\n",
        "import psutil\n",
        "import gc\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "import subprocess\n",
        "from contextlib import contextmanager\n",
        "from typing import Optional, Dict, Any\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import imageio\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from copy import deepcopy\n",
        "from vizdoom import DoomGame, ScreenFormat, ScreenResolution, Mode  # Import DoomGame\n",
        "\n",
        "# --- Create config.yaml if it doesn't exist ---\n",
        "CONFIG_PATH = \"config.yaml\"  # Path to your config file\n",
        "\n",
        "default_config = {\n",
        "    \"drive_model_dir\": \"/content/drive/My Drive/ViZDoomModels\",\n",
        "    \"drive_wad_dir\": \"/content/drive/My Drive/ViZDoomWADs\",\n",
        "    \"local_wad_dir\": \"/content/ViZDoomWADs\",\n",
        "    \"video_dir\": \"/content/drive/My Drive/ViZDoomRecordings\",\n",
        "    \"video_filename\": \"game_recording.mp4\",\n",
        "    \"record_lmp\": False,\n",
        "    \"record_video\": True,\n",
        "    \"video_fps\": 30,\n",
        "    \"lmp_dir\": \"lmp_recordings\",\n",
        "    \"scenario_name\": \"defend_the_center.cfg\",\n",
        "    \"stack_size\": 4,\n",
        "    \"num_episodes\": 10,\n",
        "    \"frame_skip_training\": 4,\n",
        "    \"frame_skip_recording\": 1,\n",
        "    \"gamma\": 0.99,\n",
        "    \"epsilon_start\": 1.0,\n",
        "    \"epsilon_end\": 0.05,\n",
        "    \"epsilon_decay\": 0.995,\n",
        "    \"model_save_freq\": 10,\n",
        "    \"batch_size\": 64,\n",
        "    \"memory_capacity\": 10000,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"tau\": 0.005,\n",
        "    \"n_step\": 3,\n",
        "    \"grad_clip_norm\": 1.0,\n",
        "    \"epsilon_decay_rate_step\": 1000,\n",
        "    \"use_best_model_callback\": True,\n",
        "    \"best_model_smoothing_window\": 10,\n",
        "    \"validation_episodes\": 5,\n",
        "}\n",
        "\n",
        "if not os.path.exists(CONFIG_PATH):\n",
        "    with open(CONFIG_PATH, 'w') as f:\n",
        "        yaml.dump(default_config, f)\n",
        "\n",
        "# --- Configuration Loading ---\n",
        "def load_config(config_path=CONFIG_PATH):\n",
        "    with open(config_path, 'r') as file:\n",
        "        return yaml.safe_load(file)\n",
        "\n",
        "CONFIG = load_config()\n",
        "\n",
        "# --- Logging Setup ---\n",
        "def setup_logger(log_dir, timestamp):\n",
        "    log_file = os.path.join(log_dir, f\"training_{timestamp}.log\")\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    # Clear any existing handlers\n",
        "    if logger.hasHandlers():\n",
        "        logger.handlers.clear()\n",
        "\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "\n",
        "    file_handler = logging.FileHandler(log_file)\n",
        "    file_handler.setLevel(logging.DEBUG)\n",
        "    stream_handler = logging.StreamHandler()\n",
        "    stream_handler.setLevel(logging.INFO)\n",
        "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "    file_handler.setFormatter(formatter)\n",
        "    stream_handler.setFormatter(formatter)\n",
        "    logger.addHandler(file_handler)\n",
        "    logger.addHandler(stream_handler)\n",
        "    return logger\n",
        "\n",
        "# --- Google Drive Setup ---\n",
        "DRIVE_MODEL_DIR = CONFIG[\"drive_model_dir\"]\n",
        "DRIVE_WAD_DIR = CONFIG[\"drive_wad_dir\"]\n",
        "LOCAL_WAD_DIR = CONFIG[\"local_wad_dir\"]\n",
        "VIDEO_DIR = CONFIG[\"video_dir\"]\n",
        "VIDEO_FILENAME = CONFIG[\"video_filename\"]\n",
        "VIDEO_PATH = os.path.join(VIDEO_DIR, VIDEO_FILENAME)\n",
        "\n",
        "# --- Configuration Variables ---\n",
        "RECORD_LMP = CONFIG[\"record_lmp\"]\n",
        "RECORD_VIDEO = CONFIG[\"record_video\"]\n",
        "VIDEO_FPS = CONFIG[\"video_fps\"]\n",
        "LMP_DIR = CONFIG[\"lmp_dir\"]\n",
        "SCENARIO_NAME = CONFIG[\"scenario_name\"]\n",
        "STACK_SIZE = CONFIG[\"stack_size\"]\n",
        "NUM_EPISODES = CONFIG[\"num_episodes\"]\n",
        "FRAME_SKIP_TRAINING = CONFIG[\"frame_skip_training\"]\n",
        "FRAME_SKIP_RECORDING = CONFIG[\"frame_skip_recording\"]\n",
        "\n",
        "# --- Training Parameters ---\n",
        "GAMMA = CONFIG[\"gamma\"]\n",
        "EPSILON_START = CONFIG[\"epsilon_start\"]\n",
        "EPSILON_END = CONFIG[\"epsilon_end\"]\n",
        "EPSILON_DECAY = CONFIG[\"epsilon_decay\"]\n",
        "MODEL_SAVE_FREQ = CONFIG[\"model_save_freq\"]\n",
        "BATCH_SIZE = CONFIG[\"batch_size\"]\n",
        "MEMORY_CAPACITY = CONFIG[\"memory_capacity\"]\n",
        "LEARNING_RATE = CONFIG[\"learning_rate\"]\n",
        "TAU = CONFIG[\"tau\"]\n",
        "N_STEP = CONFIG[\"n_step\"]\n",
        "GRAD_CLIP_NORM = CONFIG[\"grad_clip_norm\"]\n",
        "EPSILON_DECAY_RATE_STEP = CONFIG[\"epsilon_decay_rate_step\"]\n",
        "USE_BEST_MODEL_CALLBACK = CONFIG[\"use_best_model_callback\"]\n",
        "BEST_MODEL_SMOOTHING_WINDOW = CONFIG[\"best_model_smoothing_window\"]\n",
        "VALIDATION_EPISODES = CONFIG[\"validation_episodes\"]\n",
        "\n",
        "# --- Setup Google Drive ---\n",
        "def setup_google_drive(logger):\n",
        "    drive_mounted = os.path.exists('/content/drive/My Drive')\n",
        "    if not drive_mounted:\n",
        "        try:\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/drive')\n",
        "            logger.info(\"Google Drive mounted successfully.\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error mounting Google Drive: {e}\")\n",
        "            return False\n",
        "\n",
        "    os.makedirs(VIDEO_DIR, exist_ok=True)\n",
        "    os.makedirs(DRIVE_MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(DRIVE_WAD_DIR, exist_ok=True)\n",
        "    os.makedirs(LOCAL_WAD_DIR, exist_ok=True)\n",
        "    logger.info(\"Google Drive directories created successfully.\")\n",
        "    return True\n",
        "\n",
        "def copy_scenarios_to_drive(logger):\n",
        "    local_scenarios_dir = \"/usr/local/lib/python3.10/dist-packages/vizdoom/scenarios\"\n",
        "    wad_files = glob.glob(os.path.join(local_scenarios_dir, \"*.wad\"))\n",
        "    for wad_file in wad_files:\n",
        "        dest_file = os.path.join(DRIVE_WAD_DIR, os.path.basename(wad_file))\n",
        "        if os.path.exists(dest_file):\n",
        "            logger.info(f\"Skipped existing: {os.path.basename(wad_file)}\")\n",
        "        else:\n",
        "            try:\n",
        "                shutil.copy(wad_file, dest_file)\n",
        "                logger.info(f\"Copied: {os.path.basename(wad_file)}\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error copying: {os.path.basename(wad_file)}, error: {e}\")\n",
        "    return True\n",
        "\n",
        "# --- User Input for Recording ---\n",
        "def get_record_choices(logger):\n",
        "    logger.info(f\"Record LMP: {RECORD_LMP}, Record Video: {RECORD_VIDEO}\")\n",
        "    return RECORD_LMP, RECORD_VIDEO\n",
        "\n",
        "# --- User Input for Training Episodes ---\n",
        "def get_num_episodes(logger):\n",
        "    logger.info(f\"Number of Episodes: {NUM_EPISODES}\")\n",
        "    return NUM_EPISODES\n",
        "\n",
        "# --- User Input for FRAME_SKIP ---\n",
        "def get_frame_skips(logger):\n",
        "    FRAME_SKIP = FRAME_SKIP_TRAINING if not RECORD_VIDEO else FRAME_SKIP_RECORDING\n",
        "    logger.info(f\"Frame Skip Training: {FRAME_SKIP_TRAINING}, Frame Skip Recording: {FRAME_SKIP_RECORDING}\")\n",
        "    return FRAME_SKIP_TRAINING, FRAME_SKIP_RECORDING, FRAME_SKIP\n",
        "\n",
        "def get_wad_choice(logger):\n",
        "    print(\"Choose a WAD file to use:\")\n",
        "    print(\"1. Use current scenario WAD (defend_the_center.cfg with vizdoom assets)\")\n",
        "    print(\"2. Use original Doom WAD from Google Drive (ViZDoomWADs folder with defend_the_center.cfg)\")\n",
        "    wad_choice = input(\"Enter your choice (1 or 2): \")\n",
        "    logger.info(f\"WAD Choice: {wad_choice}\")\n",
        "    return wad_choice\n",
        "\n",
        "def setup_scenario(wad_choice, logger):\n",
        "    global SCENARIO_NAME\n",
        "    SCENARIO_NAME = \"defend_the_center.cfg\"\n",
        "\n",
        "    if wad_choice == \"1\":\n",
        "        try:\n",
        "            import vizdoom\n",
        "            vizdoom_path = os.path.dirname(vizdoom.__file__)\n",
        "            SCENARIO_PATH = os.path.join(vizdoom_path, \"scenarios\", SCENARIO_NAME)\n",
        "            wad_path = None\n",
        "            logger.info(f\"Using default scenario path: {SCENARIO_PATH}\")\n",
        "            return SCENARIO_PATH, wad_path\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading default scenario: {e}\")\n",
        "            # Fallback: Try to use a path relative to the current file\n",
        "            SCENARIO_PATH = os.path.join(\"scenarios\", SCENARIO_NAME)\n",
        "            logger.warning(f\"Trying fallback scenario path: {SCENARIO_PATH}\")\n",
        "            return SCENARIO_PATH, None\n",
        "\n",
        "    elif wad_choice == \"2\":\n",
        "        wad_files = glob.glob(os.path.join(DRIVE_WAD_DIR, \"*.wad\"))\n",
        "        if not wad_files:\n",
        "            logger.warning(\"No WAD files found in ViZDoomWADs. Using default scenario.\")\n",
        "            return setup_scenario(\"1\", logger)\n",
        "        print(\"Available WAD files in ViZDoomWADs:\")\n",
        "        for i, file in enumerate(wad_files):\n",
        "            print(f\"{i+1}. {os.path.basename(file)}\")\n",
        "        wad_file_choice = input(\"Enter the number of the WAD file to use: \")\n",
        "        try:\n",
        "            wad_file_choice = int(wad_file_choice)\n",
        "            if 1 <= wad_file_choice <= len(wad_files):\n",
        "                wad_path = wad_files[wad_file_choice - 1]\n",
        "                local_wad_path = os.path.join(LOCAL_WAD_DIR, os.path.basename(wad_path))\n",
        "                if not os.path.exists(local_wad_path):\n",
        "                    print(f\"Copying {os.path.basename(wad_path)} from Google Drive to local...\")\n",
        "                    try:\n",
        "                        shutil.copy(wad_path, local_wad_path)\n",
        "                        logger.info(f\"Copied {os.path.basename(wad_path)} from Google Drive to local.\")\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"Error copying wad file to local: {e}\")\n",
        "                        return setup_scenario(\"1\", logger)\n",
        "                else:\n",
        "                    print(f\"{os.path.basename(wad_path)} already exists locally. Using local copy.\")\n",
        "                    logger.info(f\"{os.path.basename(wad_path)} already exists locally.\")\n",
        "                wad_path = local_wad_path\n",
        "                import vizdoom\n",
        "                vizdoom_path = os.path.dirname(vizdoom.__file__)\n",
        "                SCENARIO_PATH = os.path.join(vizdoom_path, \"scenarios\", SCENARIO_NAME)\n",
        "                logger.info(f\"Using WAD file: {wad_path}, scenario path: {SCENARIO_PATH}\")\n",
        "                return SCENARIO_PATH, wad_path\n",
        "            else:\n",
        "                logger.warning(\"Invalid WAD file choice. Using default scenario.\")\n",
        "                return setup_scenario(\"1\", logger)\n",
        "        except ValueError:\n",
        "            logger.warning(\"Invalid input. Using default scenario.\")\n",
        "            return setup_scenario(\"1\", logger)\n",
        "    else:\n",
        "        logger.warning(\"Invalid choice. Using default scenario.\")\n",
        "        return setup_scenario(\"1\", logger)\n",
        "\n",
        "# --- Optimized DQN for T4 GPU ---\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        self.use_checkpointing = True\n",
        "\n",
        "        # Optimized conv layers with T4-specific settings\n",
        "        self.conv1 = nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # Calculate conv output size\n",
        "        conv_out_size = self._get_conv_output(input_shape)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(conv_out_size, 512)\n",
        "        self.fc2 = nn.Linear(512, num_actions)\n",
        "\n",
        "        # Initialize with kaiming\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "        # Enable mixed precision for T4\n",
        "        self.use_amp = True\n",
        "\n",
        "        # T4 optimizations\n",
        "        if torch.cuda.is_available():\n",
        "            torch.backends.cudnn.benchmark = True\n",
        "            if torch.cuda.get_device_properties(0).name == 'Tesla T4':\n",
        "                torch.set_float32_matmul_precision('high')\n",
        "\n",
        "    def _get_conv_output(self, shape):\n",
        "        \"\"\"Helper method to calculate conv output dimensions\"\"\"\n",
        "        with torch.no_grad():\n",
        "            input = torch.zeros(1, *shape)\n",
        "            x = F.relu(self.bn1(self.conv1(input)))\n",
        "            x = F.relu(self.bn2(self.conv2(x)))\n",
        "            x = F.relu(self.bn3(self.conv3(x)))\n",
        "            return x.numel() // x.shape[0]\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Use AMP context if enabled\n",
        "        with torch.cuda.amp.autocast() if self.use_amp else nullcontext():\n",
        "            if self.use_checkpointing and self.training:\n",
        "                x = torch.utils.checkpoint.checkpoint(self.conv_forward, x, use_reentrant=False)\n",
        "            else:\n",
        "                x = self.conv_forward(x)\n",
        "            x = self.fc_forward(x)\n",
        "        return x\n",
        "\n",
        "    def conv_forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "    def fc_forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class NoisyLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, std_init=0.4):\n",
        "        super(NoisyLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.std_init = std_init\n",
        "\n",
        "        self.weight_mu = nn.Parameter(torch.empty(out_features, in_features))\n",
        "        self.weight_sigma = nn.Parameter(torch.empty(out_features, in_features))\n",
        "        self.register_buffer('weight_epsilon', torch.empty(out_features, in_features))\n",
        "\n",
        "        self.bias_mu = nn.Parameter(torch.empty(out_features))\n",
        "        self.bias_sigma = nn.Parameter(torch.empty(out_features))\n",
        "        self.register_buffer('bias_epsilon', torch.empty(out_features))\n",
        "\n",
        "        self.reset_parameters()\n",
        "        self.reset_noise()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        mu_range = 1 / math.sqrt(self.in_features)\n",
        "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
        "        self.weight_sigma.data.fill_(self.std_init / math.sqrt(self.in_features))\n",
        "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
        "        self.bias_sigma.data.fill_(self.std_init / math.sqrt(self.out_features))\n",
        "\n",
        "    def reset_noise(self):\n",
        "        epsilon_in = self._scale_noise(self.in_features)\n",
        "        epsilon_out = self._scale_noise(self.out_features)\n",
        "        self.weight_epsilon.copy_(epsilon_out.outer(epsilon_in))\n",
        "        self.bias_epsilon.copy_(epsilon_out)\n",
        "\n",
        "    def _scale_noise(self, size):\n",
        "        x = torch.randn(size)\n",
        "        return x.sign().mul_(x.abs().sqrt_())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.linear(x,\n",
        "                       self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
        "                       self.bias_mu + self.bias_sigma * self.bias_epsilon)\n",
        "\n",
        "class DuelingDQN(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions, use_noisy=True):\n",
        "        super(DuelingDQN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "\n",
        "        conv_out_size = self._get_conv_output(input_shape)\n",
        "\n",
        "        # Value stream\n",
        "        if use_noisy:\n",
        "            self.value_fc = NoisyLinear(conv_out_size, 512)\n",
        "            self.value = NoisyLinear(512, 1)\n",
        "        else:\n",
        "            self.value_fc = nn.Linear(conv_out_size, 512)\n",
        "            self.value = nn.Linear(512, 1)\n",
        "\n",
        "        # Advantage stream\n",
        "        if use_noisy:\n",
        "            self.advantage_fc = NoisyLinear(conv_out_size, 512)\n",
        "            self.advantage = NoisyLinear(512, num_actions)\n",
        "        else:\n",
        "            self.advantage_fc = nn.Linear(conv_out_size, 512)\n",
        "            self.advantage = nn.Linear(512, num_actions)\n",
        "\n",
        "        self.use_noisy = use_noisy\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def _get_conv_output(self, shape):\n",
        "        o = torch.zeros(1, *shape)\n",
        "        o = F.relu(self.conv1(o))\n",
        "        o = F.relu(self.conv2(o))\n",
        "        o = F.relu(self.conv3(o))\n",
        "        return int(np.prod(o.size()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        value = F.relu(self.value_fc(x))\n",
        "        value = self.value(value)\n",
        "\n",
        "        advantage = F.relu(self.advantage_fc(x))\n",
        "        advantage = self.advantage(advantage)\n",
        "\n",
        "        return value + advantage - advantage.mean(dim=1, keepdim=True)\n",
        "\n",
        "    def reset_noise(self):\n",
        "        if self.use_noisy:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, NoisyLinear):\n",
        "                    m.reset_noise()\n",
        "\n",
        "# --- Prioritized Experience Replay Memory ---\n",
        "class PrioritizedReplayMemory:\n",
        "    def __init__(self, capacity, alpha=0.6, beta_start=0.4, beta_frames=100000):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "        self.priorities = np.zeros(capacity, dtype=np.float32)\n",
        "        self.alpha = alpha\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_frames = beta_frames\n",
        "        self.frame = 0\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        max_priority = self.priorities.max() if self.memory else 1.0\n",
        "\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "\n",
        "        self.memory[self.position] = (state, action, reward, next_state, done)\n",
        "        self.priorities[self.position] = max_priority\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        priorities = self.priorities[:len(self.memory)]\n",
        "        probabilities = priorities**self.alpha\n",
        "        probabilities /= probabilities.sum()\n",
        "\n",
        "        indices = np.random.choice(len(self.memory), batch_size, p=probabilities)\n",
        "        samples = [self.memory[idx] for idx in indices]\n",
        "\n",
        "        beta = min(1.0, self.beta_start + (self.frame * (1 - self.beta_start) / self.beta_frames))\n",
        "        weights = (len(self.memory) * probabilities[indices])**(-beta)\n",
        "        weights /= weights.max()\n",
        "        self.frame += 1\n",
        "\n",
        "        return samples, indices, weights\n",
        "\n",
        "    def update_priorities(self, indices, td_errors):\n",
        "        self.priorities[indices] = np.abs(td_errors) + 1e-6\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "# --- N-step Buffer ---\n",
        "class NStepBuffer:\n",
        "    def __init__(self, n_step):\n",
        "        self.n_step = n_step\n",
        "        self.buffer = []\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def get(self):\n",
        "        if len(self.buffer) < self.n_step:\n",
        "            return None\n",
        "\n",
        "        n_step_state, n_step_action, n_step_reward, n_step_next_state, n_step_done = self.buffer[0]\n",
        "        for i in range(1, self.n_step):\n",
        "            state, action, reward, next_state, done = self.buffer[i]\n",
        "            n_step_reward += reward * GAMMA**i\n",
        "            n_step_next_state = next_state\n",
        "            n_step_done = done or n_step_done\n",
        "\n",
        "        self.buffer = self.buffer[1:]\n",
        "        return n_step_state, n_step_action, n_step_reward, n_step_next_state, n_step_done\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "# --- DQNAgent ---\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_shape, num_actions, learning_rate, gamma, epsilon_start, epsilon_end, epsilon_decay, memory_capacity, batch_size, tau, n_step, grad_clip_norm, epsilon_decay_rate_step):\n",
        "        self.state_shape = state_shape\n",
        "        self.num_actions = num_actions\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon_start\n",
        "        self.epsilon_start = epsilon_start\n",
        "        self.epsilon_end = epsilon_end\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.batch_size = batch_size\n",
        "        self.tau = tau\n",
        "        self.grad_clip_norm = grad_clip_norm\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.policy_net = DQN(state_shape, num_actions).to(self.device)\n",
        "        self.target_net = DQN(state_shape, num_actions).to(self.device)\n",
        "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "        self.target_net.eval()\n",
        "\n",
        "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=learning_rate)\n",
        "        self.memory = PrioritizedReplayMemory(memory_capacity)\n",
        "        self.n_step_buffer = NStepBuffer(n_step)\n",
        "        self.epsilon_decay_rate_step = epsilon_decay_rate_step\n",
        "        self.training_step = 0\n",
        "        self.best_avg_reward = float('-inf')\n",
        "        self.best_model_state = None\n",
        "\n",
        "    def select_action(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(self.num_actions)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                state = torch.tensor(state, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
        "                q_values = self.policy_net(state)\n",
        "                return q_values.argmax(dim=1).item()\n",
        "\n",
        "    def update_epsilon(self):\n",
        "        self.epsilon = max(self.epsilon_end, self.epsilon_start * (self.epsilon_decay ** (self.training_step / self.epsilon_decay_rate_step)))\n",
        "\n",
        "    def learn(self):\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return None, None, None\n",
        "        self.training_step += 1\n",
        "        samples, indices, weights = self.memory.sample(self.batch_size)\n",
        "        batch = tuple(zip(*samples))\n",
        "\n",
        "        state_batch = torch.tensor(np.array(batch[0]), dtype=torch.float32, device=self.device)\n",
        "        action_batch = torch.tensor(batch[1], dtype=torch.long, device=self.device).unsqueeze(1)\n",
        "        reward_batch = torch.tensor(batch[2], dtype=torch.float32, device=self.device).unsqueeze(1)\n",
        "        next_state_batch = torch.tensor(np.array(batch[3]), dtype=torch.float32, device=self.device)\n",
        "        done_batch = torch.tensor(batch[4], dtype=torch.float32, device=self.device).unsqueeze(1)\n",
        "        weights = torch.tensor(weights, dtype=torch.float32, device=self.device).unsqueeze(1)\n",
        "\n",
        "        q_values = self.policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            next_q_values_online = self.policy_net(next_state_batch)\n",
        "            next_actions = next_q_values_online.argmax(dim=1).unsqueeze(1)\n",
        "            next_q_values_target = self.target_net(next_state_batch).gather(1, next_actions)\n",
        "            expected_q_values = reward_batch + self.gamma * next_q_values_target * (1 - done_batch)\n",
        "\n",
        "        td_errors = expected_q_values - q_values\n",
        "        loss = (weights * F.smooth_l1_loss(q_values, expected_q_values, reduction='none')).mean()\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), self.grad_clip_norm)\n",
        "        self.optimizer.step()\n",
        "\n",
        "        self.memory.update_priorities(indices, td_errors.detach().cpu().numpy().squeeze())\n",
        "        return loss.item(), q_values.mean().item(), torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), self.grad_clip_norm).item()\n",
        "\n",
        "    def update_target_network(self):\n",
        "        for target_param, local_param in zip(self.target_net.parameters(), self.policy_net.parameters()):\n",
        "            target_param.data.copy_(self.tau * local_param.data + (1.0 - self.tau) * target_param.data)\n",
        "\n",
        "    def save_model(self, model_path):\n",
        "        torch.save({\n",
        "            'policy_net_state_dict': self.policy_net.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "        }, model_path)\n",
        "\n",
        "    def load_model(self, model_path):\n",
        "        checkpoint = torch.load(model_path, map_location=self.device)\n",
        "        self.policy_net.load_state_dict(checkpoint['policy_net_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "\n",
        "def scan_for_models(agent, model_dir, logger):\n",
        "    model_files = glob.glob(os.path.join(model_dir, \"*.pth\"))\n",
        "\n",
        "    if not model_files:\n",
        "        logger.info(\"No existing models found. Creating new model...\")\n",
        "        return agent  # Return the existing agent instead of creating new one\n",
        "\n",
        "    print(\"Available models:\")\n",
        "    for i, file in enumerate(model_files):\n",
        "        print(f\"{i+1}. {os.path.basename(file)}\")\n",
        "    print(f\"{len(model_files)+1}. Create new model\")\n",
        "\n",
        "    choice = input(\"Enter your choice: \")\n",
        "    try:\n",
        "        choice = int(choice)\n",
        "        if choice in range(1, len(model_files) + 2):\n",
        "            if choice <= len(model_files):\n",
        "                model_path = model_files[choice - 1]\n",
        "                try:\n",
        "                    agent.load_model(model_path)\n",
        "                    logger.info(f\"Model loaded from {model_path}\")\n",
        "                    return agent\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error loading model: {e}\")\n",
        "                    return agent  # Return existing agent on error\n",
        "            else:\n",
        "                logger.info(\"Creating new model...\")\n",
        "                return agent  # Return existing agent for new model\n",
        "        else:\n",
        "            logger.warning(\"Invalid choice. Using existing model.\")\n",
        "            return agent\n",
        "    except ValueError:\n",
        "        logger.warning(\"Invalid input. Using existing model.\")\n",
        "        return agent\n",
        "\n",
        "def setup_vizdoom(scenario_path, wad_path=None, logger=None):\n",
        "    try:\n",
        "        from vizdoom import DoomGame, ScreenFormat, ScreenResolution, Mode\n",
        "        game = DoomGame()\n",
        "\n",
        "        if scenario_path:\n",
        "            game.load_config(scenario_path)\n",
        "        else:\n",
        "            raise ValueError(\"Scenario path is not defined.\")\n",
        "\n",
        "        if wad_path:\n",
        "            game.set_doom_game_path(wad_path)\n",
        "        game.set_window_visible(False)\n",
        "        game.set_screen_format(ScreenFormat.RGB24)\n",
        "        game.set_screen_resolution(ScreenResolution.RES_320X240)\n",
        "\n",
        "        if RECORD_LMP:\n",
        "            game.set_mode(Mode.PLAYER)\n",
        "            os.makedirs(LMP_DIR, exist_ok=True)\n",
        "\n",
        "        game.init()\n",
        "        num_actions = game.get_available_buttons_size()\n",
        "        actions = np.identity(num_actions, dtype=int).tolist()\n",
        "\n",
        "        screen_height, screen_width = game.get_screen_height(), game.get_screen_width()\n",
        "        channels = game.get_screen_channels()\n",
        "        state_shape = (STACK_SIZE * channels, 84, 84)\n",
        "        logger.info(\"ViZDoom initialized successfully.\")\n",
        "        return game, actions, state_shape\n",
        "    except Exception as e:\n",
        "        if logger:\n",
        "            logger.error(f\"Error during ViZDoom setup: {e}\")\n",
        "        print(f\"Error during ViZDoom setup: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "# --- Video Writer ---\n",
        "def setup_video_writer(video_dir, video_fps, logger=None):\n",
        "    \"\"\"Setup video writer with timestamped filename\"\"\"\n",
        "    if RECORD_VIDEO:\n",
        "        try:\n",
        "            # Create timestamp prefix\n",
        "            timestamp = datetime.now().strftime(\"%y%m%d%H%M\")\n",
        "            video_filename = f\"{timestamp}_game_recording.mp4\"\n",
        "            video_path = os.path.join(video_dir, video_filename)\n",
        "\n",
        "            # Create video writer\n",
        "            video_writer = imageio.get_writer(video_path, fps=video_fps)\n",
        "            if logger:\n",
        "                logger.info(f\"Video Writer setup at: {video_path}\")\n",
        "            return video_writer, video_path\n",
        "\n",
        "        except Exception as e:\n",
        "            if logger:\n",
        "                logger.error(f\"Error during video writer setup: {e}\")\n",
        "            return None, None\n",
        "    return None, None\n",
        "\n",
        "@contextmanager\n",
        "def video_writer_context(video_dir, video_fps, logger):\n",
        "    \"\"\"Context manager for video writer\"\"\"\n",
        "    writer = None\n",
        "    path = None\n",
        "    try:\n",
        "        writer, path = setup_video_writer(video_dir, video_fps, logger)\n",
        "        yield writer, path\n",
        "    finally:\n",
        "        if writer:\n",
        "            try:\n",
        "                writer.close()\n",
        "                if logger and path:\n",
        "                    logger.info(f\"Video saved to: {path}\")\n",
        "            except Exception as e:\n",
        "                if logger:\n",
        "                    logger.error(f\"Error closing video writer: {e}\")\n",
        "\n",
        "# --- TensorBoard Setup ---\n",
        "def setup_tensorboard(log_dir, logger=None):\n",
        "    now = datetime.now()\n",
        "    dt_string = now.strftime(\"%Y%m%d%H%M\")\n",
        "    log_dir = os.path.join(log_dir, f\"{dt_string}_experiment\")\n",
        "    if logger:\n",
        "      logger.info(f\"TensorBoard logging to: {log_dir}\")\n",
        "    return SummaryWriter(log_dir=log_dir)\n",
        "\n",
        "# --- Frame Stacking ---\n",
        "def preprocess_frame(frames):\n",
        "    if len(frames) == 0:\n",
        "        return []\n",
        "    processed_frames = []\n",
        "    for frame in frames:\n",
        "        if len(frame.shape) == 3 and frame.shape[0] == 3:\n",
        "            frame = np.mean(frame, axis=0)\n",
        "        frame = frame.astype(np.float32) / 255.0\n",
        "        frame = cv2.resize(frame, (84, 84), interpolation=cv2.INTER_AREA)\n",
        "        if len(frame.shape) == 3:\n",
        "            frame = frame.transpose(2, 0, 1)\n",
        "        else:\n",
        "            frame = np.expand_dims(frame, axis=0)\n",
        "        processed_frames.append(frame)\n",
        "    return processed_frames\n",
        "\n",
        "def create_stacked_state(state_buffer):\n",
        "    processed_frames = preprocess_frame(state_buffer)\n",
        "    if any(f is None for f in processed_frames) or not all(f.shape == processed_frames[0].shape for f in processed_frames):\n",
        "        print(\"Error: Inconsistent or None frames in processed_frames\")\n",
        "        return None\n",
        "    stacked_state = np.concatenate(processed_frames, axis=0)\n",
        "    return stacked_state\n",
        "\n",
        "def get_game_state_info(game):\n",
        "    game_state = game.get_state()\n",
        "    if game_state is not None:\n",
        "        damage_taken = game_state.game_variables[0]\n",
        "        damage_inflicted = game_state.game_variables[1]\n",
        "        return damage_taken, damage_inflicted\n",
        "    else:\n",
        "        return 0, 0\n",
        "\n",
        "def run_episode(agent, game, actions, episode, frame_skip, lmp_dir, record_video, video_writer, stack_size, state_shape, logger, episode_metrics_df):\n",
        "    with resource_cleanup():\n",
        "        if RECORD_LMP:\n",
        "            lmp_file_path = os.path.join(lmp_dir, f\"episode_{episode + 1}.lmp\")\n",
        "            game.new_episode(lmp_file_path)\n",
        "        else:\n",
        "            game.new_episode()\n",
        "\n",
        "        game_state = game.get_state()\n",
        "        if game_state is None or game_state.screen_buffer is None:\n",
        "            logger.error(f\"Skipping episode {episode+1} due to invalid game state.\")\n",
        "            return None, 0, 0, 0, 0, 0, None\n",
        "\n",
        "        state_buffer = [game_state.screen_buffer] * stack_size\n",
        "        state = create_stacked_state(state_buffer)\n",
        "        if state is None:\n",
        "            logger.error(f\"Skipping episode {episode + 1} due to state initialization error.\")\n",
        "            return None, 0, 0, 0, 0, 0, None\n",
        "\n",
        "        total_reward = 0\n",
        "        step_count = 0\n",
        "        episode_start_time = time.time()\n",
        "        damage_taken = 0\n",
        "        damage_inflicted = 0\n",
        "        action_counts = Counter()\n",
        "        inference_times = []\n",
        "        loss, avg_q_value, grad_norm = None, None, None\n",
        "\n",
        "        while not game.is_episode_finished():\n",
        "            inference_start_time = time.time()\n",
        "\n",
        "            action_index = agent.select_action(state)\n",
        "\n",
        "            inference_end_time = time.time()\n",
        "            inference_times.append(inference_end_time - inference_start_time)\n",
        "\n",
        "            action = actions[action_index]\n",
        "            action_counts[action_index] += 1\n",
        "\n",
        "            reward = game.make_action(action, frame_skip)\n",
        "            done = game.is_episode_finished()\n",
        "\n",
        "            if not done:\n",
        "                game_state = game.get_state()\n",
        "                if game_state and game_state.screen_buffer is not None:\n",
        "                    next_frame = game_state.screen_buffer\n",
        "                    state_buffer.pop(0)\n",
        "                    state_buffer.append(next_frame)\n",
        "                    next_state = create_stacked_state(state_buffer)\n",
        "\n",
        "                    if next_state is None:\n",
        "                        logger.error(f\"Error: next_state is None in episode {episode + 1} at step {step_count + 1}.\")\n",
        "                        break\n",
        "                    damage_taken_step, damage_inflicted_step = get_game_state_info(game)\n",
        "                    damage_taken += damage_taken_step\n",
        "                    damage_inflicted += damage_inflicted_step\n",
        "                else:\n",
        "                    logger.error(f\"Error: Invalid state in episode {episode+1}, step {step_count+1}.\")\n",
        "                    next_state = np.zeros(state_shape)\n",
        "                    break\n",
        "            else:\n",
        "                next_state = np.zeros(state_shape)\n",
        "\n",
        "            agent.n_step_buffer.push(state, action_index, reward, next_state, done)\n",
        "\n",
        "            n_step_experience = agent.n_step_buffer.get()\n",
        "            if n_step_experience:\n",
        "                n_step_state, n_step_action, n_step_reward, n_step_next_state, n_step_done = n_step_experience\n",
        "                agent.memory.push(n_step_state, n_step_action, n_step_reward, n_step_next_state, n_step_done)\n",
        "\n",
        "            loss_step, avg_q_value_step, grad_norm_step = agent.learn()\n",
        "            if loss_step is not None:\n",
        "                loss = loss_step\n",
        "                avg_q_value = avg_q_value_step\n",
        "                grad_norm = grad_norm_step\n",
        "\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "            step_count += 1\n",
        "\n",
        "            if record_video and not done:\n",
        "                most_recent_frame = state_buffer[-1]\n",
        "                try:\n",
        "                    # Add frame counter overlay\n",
        "                    frame_counter = f\"Episode {episode+1} Step {step_count}\"\n",
        "                    cv2.putText(most_recent_frame, frame_counter, (10, 30),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
        "\n",
        "                    video_writer.append_data(most_recent_frame)\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error appending frame to video: {e}\")\n",
        "                    break\n",
        "\n",
        "        episode_survival_time = time.time() - episode_start_time\n",
        "        total_actions = sum(action_counts.values())\n",
        "        if total_actions > 0:\n",
        "            action_diversity = sum(count / total_actions for count in action_counts.values()) / len(actions)\n",
        "        else:\n",
        "            action_diversity = 0\n",
        "\n",
        "        avg_inference_time = np.mean(inference_times) if inference_times else 0\n",
        "\n",
        "        if total_reward is not None:\n",
        "            new_row = {\n",
        "                'episode': episode + 1,\n",
        "                'reward': total_reward,\n",
        "                'steps': step_count,\n",
        "                'survival_time': episode_survival_time,\n",
        "                'damage_taken': damage_taken,\n",
        "                'damage_inflicted': damage_inflicted,\n",
        "                'action_diversity': action_diversity,\n",
        "                'avg_inference_time': avg_inference_time,\n",
        "                'loss': loss if loss is not None else np.nan,\n",
        "                'avg_q_value': avg_q_value if avg_q_value is not None else np.nan,\n",
        "                'grad_norm': grad_norm if grad_norm is not None else np.nan\n",
        "            }\n",
        "            return total_reward, step_count, episode_survival_time, damage_taken, damage_inflicted, action_diversity, avg_inference_time, new_row\n",
        "        else:\n",
        "            return None, 0, 0, 0, 0, 0, 0, None\n",
        "\n",
        "    # After each episode\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# --- Validation ---\n",
        "def validate_model(agent, game, actions, state_shape, stack_size, num_episodes, logger):\n",
        "    \"\"\"Validates the model by running a number of episodes and calculating the mean reward.\"\"\"\n",
        "    total_rewards = []\n",
        "    for episode in range(num_episodes):\n",
        "        total_reward, _, _, _, _, _, _, _ = run_episode(agent, game, actions, episode, FRAME_SKIP_RECORDING, None, False, None, stack_size, state_shape, logger, pd.DataFrame())\n",
        "        if total_reward is not None:\n",
        "            total_rewards.append(total_reward)\n",
        "    return np.mean(total_rewards) if total_rewards else float('-inf')\n",
        "\n",
        "def best_model_callback(agent, episode_rewards, logger, model_dir, best_model_smoothing_window):\n",
        "    \"\"\"Callback to save the best model based on a smoothed average reward.\"\"\"\n",
        "    if len(episode_rewards) >= best_model_smoothing_window:\n",
        "        avg_reward = np.mean(episode_rewards[-best_model_smoothing_window:])\n",
        "    else:\n",
        "        avg_reward = np.mean(episode_rewards) if episode_rewards else float('-inf')\n",
        "    if avg_reward > agent.best_avg_reward:\n",
        "        agent.best_avg_reward = avg_reward\n",
        "        agent.best_model_state = deepcopy(agent.policy_net.state_dict())\n",
        "        model_filename = f\"best_dqn_model.pth\"\n",
        "        model_path = os.path.join(model_dir, model_filename)\n",
        "        agent.save_model(model_path)\n",
        "        logger.info(f\"Best model saved to {model_path} with reward: {agent.best_avg_reward}\")\n",
        "\n",
        "# --- Save metrics to CSV ---\n",
        "def save_metrics(episode_rewards, episode_lengths, episode_survival_times,\n",
        "                 episode_damage_taken, episode_damage_inflicted, logger, episode_metrics_df, training_time,\n",
        "                 ram_usage_list, gpu_memory_usage_list, action_diversity_list):\n",
        "    metrics_df = pd.DataFrame({\n",
        "    'episode': range(1, len(episode_rewards) + 1),\n",
        "    'reward': episode_rewards,\n",
        "    'steps': episode_lengths,\n",
        "    'epsilon': [EPSILON_START * (EPSILON_DECAY ** (i / EPSILON_DECAY_RATE_STEP)) for i in range(len(episode_rewards))],\n",
        "    'training_time': training_time,\n",
        "    'survival_time': episode_survival_times,\n",
        "    'damage_taken': episode_damage_taken,\n",
        "    'damage_inflicted': episode_damage_inflicted,\n",
        "        'ram_usage': ram_usage_list,\n",
        "        'gpu_memory_usage': gpu_memory_usage_list,\n",
        "        'action_diversity': action_diversity_list,\n",
        "    'model_save_freq': MODEL_SAVE_FREQ,\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'memory_capacity': MEMORY_CAPACITY,\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'tau': TAU,\n",
        "    'n_step': N_STEP\n",
        "    })\n",
        "    # Merge episode metrics with overall metrics\n",
        "    metrics_df = pd.merge(metrics_df, episode_metrics_df, on='episode', how='left')\n",
        "\n",
        "    now = datetime.now()\n",
        "    dt_string = now.strftime(\"%Y%m%d%H%M\")\n",
        "    metrics_filename = f\"{dt_string}_training_metrics.csv\"\n",
        "    metrics_path = os.path.join(DRIVE_MODEL_DIR, metrics_filename)\n",
        "    metrics_df.to_csv(metrics_path, index=False)\n",
        "    logger.info(f\"Training metrics saved to {metrics_path}\")\n",
        "\n",
        "# --- Main Training Loop ---\n",
        "def cleanup_resources():\n",
        "    # Clear memory\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "def close_writers(video_writer=None, tensorboard_writer=None):\n",
        "    try:\n",
        "        if video_writer:\n",
        "            video_writer.close()  # Use close() instead of release() for imageio writer\n",
        "        if tensorboard_writer:\n",
        "            tensorboard_writer.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Error closing writers: {e}\")\n",
        "\n",
        "def validate_input(value, param_type, min_val, max_val, default):\n",
        "    \"\"\"Validate and convert user input\"\"\"\n",
        "    if not value:  # Handle empty input\n",
        "        return default\n",
        "\n",
        "    try:\n",
        "        if param_type == \"float\":\n",
        "            val = float(value)\n",
        "        else:\n",
        "            val = int(value)\n",
        "\n",
        "        if min_val <= val <= max_val:\n",
        "            return val\n",
        "\n",
        "        print(f\"Value {val} out of range ({min_val}-{max_val}). Using default: {default}\")\n",
        "        return default\n",
        "\n",
        "    except ValueError:\n",
        "        print(f\"Invalid input '{value}'. Using default: {default}\")\n",
        "        return default\n",
        "\n",
        "def get_hyperparameters():\n",
        "    params = {\n",
        "        \"learning_rate\": {\"default\": 0.00025, \"type\": \"float\", \"min\": 0, \"max\": 1,\n",
        "                         \"desc\": \"Step size for optimizer (0-1)\"},\n",
        "        \"batch_size\": {\"default\": 64, \"type\": \"int\", \"min\": 32, \"max\": 512,\n",
        "                      \"desc\": \"Batch size for training (32-512)\"},\n",
        "        \"memory_capacity\": {\"default\": 50000, \"type\": \"int\", \"min\": 10000, \"max\": 1000000,\n",
        "                          \"desc\": \"Max experiences in memory (10k-1M)\"},\n",
        "        \"gamma\": {\"default\": 0.99, \"type\": \"float\", \"min\": 0, \"max\": 1,\n",
        "                 \"desc\": \"Discount factor (0-1)\"},\n",
        "        \"tau\": {\"default\": 0.005, \"type\": \"float\", \"min\": 0, \"max\": 1,\n",
        "                \"desc\": \"Target network update rate (0-1)\"},\n",
        "        \"epsilon_start\": {\"default\": 1.0, \"type\": \"float\", \"min\": 0, \"max\": 1,\n",
        "                         \"desc\": \"Initial exploration rate (0-1)\"},\n",
        "        \"epsilon_end\": {\"default\": 0.05, \"type\": \"float\", \"min\": 0, \"max\": 1,\n",
        "                       \"desc\": \"Final exploration rate (0-1)\"},\n",
        "        \"epsilon_decay\": {\"default\": 0.995, \"type\": \"float\", \"min\": 0, \"max\": 1,\n",
        "                         \"desc\": \"Exploration decay rate (0-1)\"},\n",
        "        \"epsilon_decay_rate_step\": {\"default\": 5000, \"type\": \"int\", \"min\": 1000, \"max\": 100000,\n",
        "                                   \"desc\": \"Steps for epsilon decay (1k-100k)\"},\n",
        "        \"n_step\": {\"default\": 3, \"type\": \"int\", \"min\": 1, \"max\": 10,\n",
        "                   \"desc\": \"Steps for n-step learning (1-10)\"},\n",
        "        \"grad_clip_norm\": {\"default\": 1.0, \"type\": \"float\", \"min\": 0, \"max\": 10,\n",
        "                          \"desc\": \"Gradient clipping norm (0-10)\"},\n",
        "        \"frame_stack_size\": {\"default\": 4, \"type\": \"int\", \"min\": 2, \"max\": 4,\n",
        "                            \"desc\": \"Number of stacked frames (2-4)\"}\n",
        "    }\n",
        "\n",
        "    print(\"\\nHyperparameter Configuration Menu\")\n",
        "    print(\"=================================\")\n",
        "\n",
        "    for param_name, param_info in params.items():\n",
        "        print(f\"\\n{param_name}: {param_info['desc']}\")\n",
        "        print(f\"Default: {param_info['default']}\")\n",
        "        user_input = input(f\"Enter value (or press Enter for default): \").strip()\n",
        "\n",
        "        if user_input:\n",
        "            params[param_name][\"value\"] = validate_input(\n",
        "                user_input,\n",
        "                param_info[\"type\"],\n",
        "                param_info[\"min\"],\n",
        "                param_info[\"max\"],\n",
        "                param_info[\"default\"]\n",
        "            )\n",
        "        else:\n",
        "            params[param_name][\"value\"] = param_info[\"default\"]\n",
        "\n",
        "    return params\n",
        "\n",
        "class ResourceMonitor:\n",
        "    def __init__(self, logger, use_gpu: bool = False):\n",
        "        self.logger = logger\n",
        "        self.use_gpu = use_gpu and torch.cuda.is_available()\n",
        "        self.process = psutil.Process()\n",
        "        if self.use_gpu:\n",
        "            self.log_gpu_info()\n",
        "\n",
        "    def log_gpu_info(self):\n",
        "        \"\"\"Log GPU device information at startup\"\"\"\n",
        "        if self.use_gpu:\n",
        "            device = torch.cuda.get_device_properties(0)\n",
        "            self.logger.info(f\"GPU Device: {device.name}\")\n",
        "            self.logger.info(f\"Total GPU Memory: {device.total_memory / 1024**2:.2f} MB\")\n",
        "            try:\n",
        "                nvidia_smi = subprocess.check_output([\"nvidia-smi\"], encoding='utf-8')\n",
        "                self.logger.info(f\"NVIDIA-SMI Output:\\n{nvidia_smi}\")\n",
        "            except:\n",
        "                self.logger.warning(\"Could not get nvidia-smi output\")\n",
        "\n",
        "    def get_system_metrics(self) -> Dict[str, Any]:\n",
        "        \"\"\"Collect system resource metrics\"\"\"\n",
        "        metrics = {\n",
        "            'process_ram_mb': self.process.memory_info().rss / 1024**2,\n",
        "            'system_ram_percent': psutil.virtual_memory().percent,\n",
        "            'available_ram_mb': psutil.virtual_memory().available / 1024**2,\n",
        "            'cpu_percent': psutil.cpu_percent(),\n",
        "            'per_cpu_percent': psutil.cpu_percent(percpu=True)\n",
        "        }\n",
        "\n",
        "        if self.use_gpu:\n",
        "            metrics.update({\n",
        "                'gpu_allocated_mb': torch.cuda.memory_allocated() / 1024**2,\n",
        "                'gpu_reserved_mb': torch.cuda.memory_reserved() / 1024**2,\n",
        "                'gpu_max_allocated_mb': torch.cuda.max_memory_allocated() / 1024**2\n",
        "            })\n",
        "            try:\n",
        "                nvidia_out = subprocess.check_output(\n",
        "                    ['nvidia-smi', '--query-gpu=utilization.gpu,temperature.gpu',\n",
        "                     '--format=csv,noheader,nounits'],\n",
        "                    encoding='utf-8'\n",
        "                )\n",
        "                gpu_util, gpu_temp = map(int, nvidia_out.strip().split(','))\n",
        "                metrics.update({\n",
        "                    'gpu_utilization': gpu_util,\n",
        "                    'gpu_temperature': gpu_temp\n",
        "                })\n",
        "            except:\n",
        "                self.logger.warning(\"Could not get NVIDIA-SMI metrics\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def log_metrics(self, tensorboard_writer, episode):\n",
        "        \"\"\"Log metrics to both logger and tensorboard\"\"\"\n",
        "        metrics = self.get_system_metrics()\n",
        "\n",
        "        # Log to tensorboard\n",
        "        for name, value in metrics.items():\n",
        "            if not isinstance(value, (list, tuple)):\n",
        "                tensorboard_writer.add_scalar(f\"Resources/{name}\", value, episode)\n",
        "\n",
        "        # Format metrics for logger\n",
        "        metrics_str = \", \".join([\n",
        "            f\"{k}: {v:.2f}\" if isinstance(v, float)\n",
        "            else f\"{k}: {v}\" for k, v in metrics.items()\n",
        "            if not isinstance(v, (list, tuple))\n",
        "        ])\n",
        "        self.logger.info(f\"Resource Usage - {metrics_str}\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "@contextmanager\n",
        "def resource_cleanup(game=None, video_writer=None, tensorboard_writer=None, agent=None):\n",
        "    \"\"\"Context manager for proper resource cleanup\"\"\"\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        try:\n",
        "            if video_writer:\n",
        "                video_writer.close()\n",
        "            if tensorboard_writer:\n",
        "                tensorboard_writer.close()\n",
        "            if game:\n",
        "                game.close()\n",
        "            if agent:\n",
        "                # Explicitly delete large objects\n",
        "                del agent.policy_net\n",
        "                del agent.target_net\n",
        "                del agent.memory\n",
        "                del agent\n",
        "\n",
        "            # Clear CUDA cache\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            # Force garbage collection\n",
        "            gc.collect()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during cleanup: {e}\")\n",
        "\n",
        "# --- Video Recording Configuration ---\n",
        "def get_video_config():\n",
        "    \"\"\"Get video recording configuration from user\"\"\"\n",
        "    try:\n",
        "        record_video = input(\"\\nEnable video recording? (y/n, default=n): \").lower().strip() == 'y'\n",
        "        frame_skip = FRAME_SKIP_RECORDING if record_video else FRAME_SKIP_TRAINING\n",
        "        video_fps = VIDEO_FPS if record_video else None\n",
        "\n",
        "        if record_video:\n",
        "            frame_skip_input = input(\"Enter frame skip rate (1-10, default=1): \").strip()\n",
        "            try:\n",
        "                frame_skip = int(frame_skip_input) if frame_skip_input else 1\n",
        "                frame_skip = max(1, min(10, frame_skip))\n",
        "            except ValueError:\n",
        "                frame_skip = 1\n",
        "                print(\"Invalid input. Using default frame skip of 1\")\n",
        "\n",
        "        return {\n",
        "            'record_video': record_video,\n",
        "            'frame_skip': frame_skip,\n",
        "            'video_fps': video_fps\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error in video config: {e}. Using defaults.\")\n",
        "        return {\n",
        "            'record_video': False,\n",
        "            'frame_skip': FRAME_SKIP_TRAINING,\n",
        "            'video_fps': None\n",
        "        }\n",
        "\n",
        "# --- Video Writer Context Manager ---\n",
        "@contextmanager\n",
        "def video_writer_context(video_dir, video_fps, logger):\n",
        "    \"\"\"Context manager for video writer with timestamped filename\"\"\"\n",
        "    writer = None\n",
        "    path = None\n",
        "    try:\n",
        "        if RECORD_VIDEO:\n",
        "            timestamp = datetime.now().strftime(\"%y%m%d%H%M\")\n",
        "            video_filename = f\"{timestamp}_game_recording.mp4\"\n",
        "            video_path = os.path.join(video_dir, video_filename)\n",
        "            writer = imageio.get_writer(video_path, fps=video_fps)\n",
        "            logger.info(f\"Video recording started: {video_path}\")\n",
        "            path = video_path\n",
        "        yield writer, path\n",
        "    finally:\n",
        "        if writer:\n",
        "            try:\n",
        "                writer.close()\n",
        "                if path:\n",
        "                    logger.info(f\"Video saved: {path}\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error closing video writer: {e}\")\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Initialize components\n",
        "        TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
        "        LOG_DIR = \"logs\"\n",
        "        os.makedirs(LOG_DIR, exist_ok=True)\n",
        "        logger = setup_logger(LOG_DIR, TIMESTAMP)\n",
        "\n",
        "        # Get video configuration once\n",
        "        video_config = get_video_config()\n",
        "        global RECORD_VIDEO, FRAME_SKIP, VIDEO_FPS\n",
        "        RECORD_VIDEO = video_config['record_video']\n",
        "        FRAME_SKIP = video_config['frame_skip']\n",
        "        VIDEO_FPS = video_config['video_fps']\n",
        "\n",
        "        # Setup environment\n",
        "        setup_google_drive(logger)\n",
        "        copy_scenarios_to_drive(logger)\n",
        "        wad_choice = get_wad_choice(logger)\n",
        "        SCENARIO_PATH, wad_path = setup_scenario(wad_choice, logger)\n",
        "        game, actions, state_shape = setup_vizdoom(SCENARIO_PATH, wad_path, logger)\n",
        "        tensorboard_writer = setup_tensorboard(\"runs\", logger)\n",
        "\n",
        "        # Get hyperparameters from user or use defaults\n",
        "        params = get_hyperparameters()\n",
        "\n",
        "        # Initialize agent with proper parameters\n",
        "        agent = DQNAgent(\n",
        "            state_shape=state_shape,\n",
        "            num_actions=len(actions),\n",
        "            learning_rate=params[\"learning_rate\"][\"value\"],\n",
        "            gamma=params[\"gamma\"][\"value\"],\n",
        "            epsilon_start=params[\"epsilon_start\"][\"value\"],\n",
        "            epsilon_end=params[\"epsilon_end\"][\"value\"],\n",
        "            epsilon_decay=params[\"epsilon_decay\"][\"value\"],\n",
        "            memory_capacity=params[\"memory_capacity\"][\"value\"],\n",
        "            batch_size=params[\"batch_size\"][\"value\"],\n",
        "            tau=params[\"tau\"][\"value\"],\n",
        "            n_step=params[\"n_step\"][\"value\"],\n",
        "            grad_clip_norm=params[\"grad_clip_norm\"][\"value\"],\n",
        "            epsilon_decay_rate_step=params[\"epsilon_decay_rate_step\"][\"value\"]\n",
        "        )\n",
        "\n",
        "        # Initialize metrics DataFrame with proper columns\n",
        "        episode_metrics_df = pd.DataFrame(columns=[\n",
        "            'episode', 'reward', 'steps', 'survival_time',\n",
        "            'damage_taken', 'damage_inflicted', 'action_diversity',\n",
        "            'avg_inference_time', 'loss', 'avg_q_value', 'grad_norm'\n",
        "        ])\n",
        "\n",
        "        # Training loop with proper resource management\n",
        "        with resource_cleanup(game, None, tensorboard_writer, agent):\n",
        "            for episode in range(NUM_EPISODES):\n",
        "                with video_writer_context(VIDEO_DIR, VIDEO_FPS, logger) as (video_writer, video_path):\n",
        "                    (total_reward, step_count, episode_survival_time,\n",
        "                     damage_taken, damage_inflicted, action_diversity,\n",
        "                     avg_inference_time, new_row) = run_episode(\n",
        "                        agent, game, actions, episode, FRAME_SKIP,\n",
        "                        LMP_DIR, RECORD_VIDEO, video_writer,\n",
        "                        STACK_SIZE, state_shape, logger, episode_metrics_df)\n",
        "\n",
        "                    if total_reward is not None:\n",
        "                        # Update metrics\n",
        "                        if new_row is not None:\n",
        "                            episode_metrics_df = pd.concat([\n",
        "                                episode_metrics_df,\n",
        "                                pd.DataFrame([new_row])\n",
        "                            ], ignore_index=True)\n",
        "\n",
        "                        # Save model periodically\n",
        "                        if episode % MODEL_SAVE_FREQ == 0:\n",
        "                            model_path = os.path.join(\n",
        "                                DRIVE_MODEL_DIR,\n",
        "                                f\"dqn_model_episode_{episode}.pth\"\n",
        "                            )\n",
        "                            agent.save_model(model_path)\n",
        "                            logger.info(f\"Model saved to {model_path}\")\n",
        "\n",
        "                        # Log episode results\n",
        "                        logger.info(\n",
        "                            f\"Episode {episode + 1}: \"\n",
        "                            f\"Reward = {total_reward:.2f}, \"\n",
        "                            f\"Steps = {step_count}, \"\n",
        "                            f\"Damage Taken = {damage_taken}, \"\n",
        "                            f\"Damage Inflicted = {damage_inflicted}\"\n",
        "                        )\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in main: {e}\")\n",
        "        raise\n",
        "    finally:\n",
        "        cleanup_resources()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pphvk99NWGhS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "52b94011-7705-4b30-af8b-e3b1da1c0065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-15-8a532c2ea7f5>, line 1394)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-8a532c2ea7f5>\"\u001b[0;36m, line \u001b[0;32m1394\u001b[0m\n\u001b[0;31m    # Rest of training loop\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JT3GRHPXe8T1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1uKx3KG8j0dj3l7O8Dh3DzTRowzB7D0wg",
      "authorship_tag": "ABX9TyMJYD7NDnO9t1k15m6GwzhK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}